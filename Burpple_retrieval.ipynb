{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Extract food names from burpples reviews\n",
    "    process in parallel and combine\n",
    "    save the objets with pickle\n",
    "\n",
    "    input :\n",
    "        burpple clean review     burpple__review__clean__20170818.p\n",
    "    saved: \n",
    "        review_with_synsets__20170913.p\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Version Infomation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "system_info: 2.7.14 |Anaconda custom (64-bit)| (default, Oct 27 2017, 18:21:12) \n",
      "[GCC 7.2.0]\n",
      "path_info: /home/yueliu/Desktop/workspace_yue\n"
     ]
    }
   ],
   "source": [
    "# python version\n",
    "import sys\n",
    "print \"system_info: %s\"%sys.version\n",
    "# current working directory\n",
    "import os\n",
    "print \"path_info: %s\"%os.getcwd() "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Retrive data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "all dates: 20171113, 20170818, 20180205, 20171114\n",
      "most recent: 20180205\n"
     ]
    }
   ],
   "source": [
    "# all possible date when data is saved\n",
    "date_list = list(set([f.split(\"__\")[-1].replace(\".p\", \"\") \n",
    "     for f in os.listdir(os.getcwd()) if (f.endswith(\".p\") and (\"__review__clean__\") in f)]))\n",
    "print (\"all dates: %s\" % \", \".join(date_list))\n",
    "recent_date = sorted(date_list)[-1]\n",
    "print (\"most recent: %s\" % recent_date)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# retrive for testing\n",
    "def retrive_file(recent_date):\n",
    "    import pickle\n",
    "    file_name = \"burpple\" + \"__review__clean__\" + recent_date + \".p\"\n",
    "    with open(file_name, 'rb') as pfile:\n",
    "        df_retrived = pickle.load(pfile)\n",
    "    print (\"retrived: %s\" % file_name)\n",
    "    return df_retrived"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "retrived: burpple__review__clean__20180205.p\n",
      "CPU times: user 17 s, sys: 268 ms, total: 17.3 s\n",
      "Wall time: 17.3 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "#file_name = \"burpple_review__clean__20170818.p\"    \n",
    "df = retrive_file(recent_date)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(323104, 10)\n"
     ]
    }
   ],
   "source": [
    "print df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Review text as unique identifier, get loc list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "286612\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review_text</th>\n",
       "      <th>loc</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td></td>\n",
       "      <td>[burppleinitial/review/--wu4Z4_, burppleinitia...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>!</td>\n",
       "      <td>[burppleinitial/review/-29WyDL8, burppleinitia...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  review_text                                                loc\n",
       "0              [burppleinitial/review/--wu4Z4_, burppleinitia...\n",
       "1           !  [burppleinitial/review/-29WyDL8, burppleinitia..."
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d = df.groupby('review_text')['loc'].apply(list).to_frame().reset_index()\n",
    "print d.shape[0]\n",
    "d.head(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Clean review text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import re\n",
    "import pandas as pd\n",
    "pd.options.mode.chained_assignment = None # default is warn\n",
    "\n",
    "def clean_name_v1(s): \n",
    "    try:\n",
    "        import re\n",
    "        s = s.replace(\"\\t\",\" \").replace(\"\\n\",\" \") \n",
    "        s = re.sub(' +',' ', s.strip()) # multiple spaces\n",
    "        return s\n",
    "    except:\n",
    "        return \"\"\n",
    "\n",
    "\n",
    "def clean_name_v2(s): \n",
    "    import re\n",
    "    s = clean_name_v1(s)\n",
    "    s = s.replace(\"w/o\", \" no \").replace(\"W/o\", \" no \").replace(\"W/O\", \" no \").replace(\"w/O\", \" no \")\n",
    "    s = s.replace(\"w/\", \" \").replace(\"W/\", \" \")\n",
    "    s = \" \".join(re.sub( r\"([A-Z])\", r\" \\1\", s).split()) #capital letter\n",
    "    # numeric + character\n",
    "    s = ' '.join([w for w in s.split() if len(re.findall('[a-zA-Z]+|\\\\d+', w))==1]) \n",
    "    s = re.sub('[^a-zA-Z\\n]', ' ', s) # other character \n",
    "    s = ' '.join( [w for w in s.split() if len(w)>1] ) #single character\n",
    "    s = re.sub(' +',' ', s.strip()) # multiple spaces\n",
    "    return s\n",
    "\n",
    "def clean_name(s):\n",
    "    s = clean_name_v2(s).lower()\n",
    "    return s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 38.6 s, sys: 0 ns, total: 38.6 s\n",
      "Wall time: 38.6 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "d[\"clean_text\"] = d[\"review_text\"].apply(clean_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "276832\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>clean_text</th>\n",
       "      <th>loc</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>aa ahsighee bowl made with frozen aa berry pur...</td>\n",
       "      <td>[burppleinitial/review/huuB1mUX]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>aa berry bowl must try every aa bowl see on th...</td>\n",
       "      <td>[burppleinitial/review/z_Y7aErb]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                          clean_text  \\\n",
       "1  aa ahsighee bowl made with frozen aa berry pur...   \n",
       "2  aa berry bowl must try every aa bowl see on th...   \n",
       "\n",
       "                                loc  \n",
       "1  [burppleinitial/review/huuB1mUX]  \n",
       "2  [burppleinitial/review/z_Y7aErb]  "
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\" clean_text as unique identifier , merge loc list\"\"\"\n",
    "d1 = d.groupby(\"clean_text\")['loc'].apply(sum).to_frame().reset_index()\n",
    "d1 = d1[d1[\"clean_text\"]!=\"\"]\n",
    "print d1.shape[0]\n",
    "d1.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\"\"\" save into multiple files \"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "28\n"
     ]
    }
   ],
   "source": [
    "df_lst = []\n",
    "import numpy as np\n",
    "for g, df in d1.groupby(np.arange(len(d1)) // 10000):\n",
    "    df_lst.append(df)\n",
    "print len(df_lst)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def save_part(i, df_part):\n",
    "    import pickle\n",
    "    import datetime   \n",
    "    today = datetime.date.today()\n",
    "    today = today.strftime('%Y%m%d') \n",
    "    file_name = \"__\".join([\"review\", today, str(i)]) + \".p\"  \n",
    "    with open(file_name, 'wb') as pfile:\n",
    "        pickle.dump(df_part, pfile)\n",
    "    print \"saved: %s\"%file_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "saved: review__20180205__0.p\n",
      "saved: review__20180205__1.p\n",
      "saved: review__20180205__2.p\n",
      "saved: review__20180205__3.p\n",
      "saved: review__20180205__4.p\n",
      "saved: review__20180205__5.p\n",
      "saved: review__20180205__6.p\n",
      "saved: review__20180205__7.p\n",
      "saved: review__20180205__8.p\n",
      "saved: review__20180205__9.p\n",
      "saved: review__20180205__10.p\n",
      "saved: review__20180205__11.p\n",
      "saved: review__20180205__12.p\n",
      "saved: review__20180205__13.p\n",
      "saved: review__20180205__14.p\n",
      "saved: review__20180205__15.p\n",
      "saved: review__20180205__16.p\n",
      "saved: review__20180205__17.p\n",
      "saved: review__20180205__18.p\n",
      "saved: review__20180205__19.p\n",
      "saved: review__20180205__20.p\n",
      "saved: review__20180205__21.p\n",
      "saved: review__20180205__22.p\n",
      "saved: review__20180205__23.p\n",
      "saved: review__20180205__24.p\n",
      "saved: review__20180205__25.p\n",
      "saved: review__20180205__26.p\n",
      "saved: review__20180205__27.p\n"
     ]
    }
   ],
   "source": [
    "for i in range(len(df_lst)):\n",
    "    df_part = df_lst[i]\n",
    "    save_part(i, df_part)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. clean review text: replace by synsets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def retrive_part(i):\n",
    "    import os\n",
    "    import pickle\n",
    "    prefix = \"review\"    \n",
    "    date_list = list(set([f.split(\"__\")[-2].replace(\".p\", \"\") \n",
    "         for f in os.listdir(os.getcwd()) if (f.endswith(\".p\") and (prefix) in f)]))\n",
    "    recent_date = sorted([s for s in date_list if len(s)==8])[-1]\n",
    "    file_name = \"__\".join([prefix, recent_date, str(i)]) + \".p\"\n",
    "    with open(file_name, 'rb') as pfile:\n",
    "        retrived = pickle.load(pfile)       \n",
    "    print (\"retrived: %s\" % file_name)\n",
    "    print \"number of reviews: %d\"%len(retrived)\n",
    "    return retrived\n",
    "\n",
    "def save_part_with_food(i, samp):\n",
    "    import pickle\n",
    "    import datetime   \n",
    "    today = datetime.date.today()\n",
    "    today = today.strftime('%Y%m%d') \n",
    "    file_name = \"__\".join([\"review_with_food\", today, str(i)]) + \".p\"  \n",
    "    with open(file_name, 'wb') as pfile:\n",
    "        pickle.dump(samp, pfile)\n",
    "    print \"saved: %s\"%file_name\n",
    "    \n",
    "def retrive_file(file_name):\n",
    "    import pickle\n",
    "    with open(file_name, 'rb') as pfile:\n",
    "        df_retrived = pickle.load(pfile)\n",
    "    print (\"retrived: %s\" % file_name)\n",
    "    return df_retrived"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "retrived: review__20180205__0.p\n",
      "number of reviews: 10000\n"
     ]
    }
   ],
   "source": [
    "i = 0\n",
    "samp = retrive_part(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>clean_text</th>\n",
       "      <th>loc</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>aa ahsighee bowl made with frozen aa berry pur...</td>\n",
       "      <td>[burppleinitial/review/huuB1mUX]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>aa berry bowl must try every aa bowl see on th...</td>\n",
       "      <td>[burppleinitial/review/z_Y7aErb]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                          clean_text  \\\n",
       "1  aa ahsighee bowl made with frozen aa berry pur...   \n",
       "2  aa berry bowl must try every aa bowl see on th...   \n",
       "\n",
       "                                loc  \n",
       "1  [burppleinitial/review/huuB1mUX]  \n",
       "2  [burppleinitial/review/z_Y7aErb]  "
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "samp.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "retrived: /home/yueliu/Desktop/workspace_yue/Documentation_201712/syn_token__20180207.p\n",
      "number of syn tokens: 1177\n"
     ]
    }
   ],
   "source": [
    "import spacy\n",
    "nlp = spacy.load('en_core_web_sm')\n",
    "\n",
    "def lemma_name(s):\n",
    "    return \" \".join([token.lemma_ for token in nlp(unicode(s, \"utf-8\"))])\n",
    "\n",
    "\"\"\" to replace syn tokens \"\"\"\n",
    "def retrive_syn_tokens():\n",
    "    import os\n",
    "    import pickle\n",
    "    prefix = \"syn_token\"  \n",
    "    token_path = \"/home/yueliu/Desktop/workspace_yue/Documentation_201712\"\n",
    "    date_list = list(set([f.split(\"__\")[-1].replace(\".p\", \"\")\n",
    "                          for f in os.listdir(token_path) if (f.endswith(\".p\")\n",
    "                                                             and prefix in f)]))\n",
    "    recent_date = sorted(date_list)[-1]\n",
    "\n",
    "    file_name = os.path.join(token_path,\"__\".join([prefix, recent_date]) + \".p\")\n",
    "    with open(file_name, 'rb') as pfile:\n",
    "        retrived = pickle.load(pfile)       \n",
    "    print (\"retrived: %s\" % file_name)\n",
    "    print \"number of syn tokens: %d\"%len(retrived)\n",
    "    return retrived\n",
    "\n",
    "def rev_dict(x):\n",
    "    \"\"\" return the first element in lst as value \"\"\"\n",
    "    return dict((x[i],x[0]) for i in range(1, len(x)))\n",
    "def merge_dicts(d_lst):\n",
    "    \"\"\" shallow copy and merge into new dict\"\"\"\n",
    "    result = {}\n",
    "    for dictionary in d_lst:\n",
    "        result.update(dictionary)\n",
    "    return result   \n",
    "\n",
    "def replace_token(s):\n",
    "    \"\"\" partial string matching \"\"\"\n",
    "    s = \" \" + s + \" \"\n",
    "    s = s.replace(\" \", \"  \")\n",
    "    for key in keys:       \n",
    "        s = s.replace(\" \" + key + \" \", \" \" + rev_lookup[key] + \" \")\n",
    "    import re\n",
    "    s = re.sub(' +',' ', s.strip()) # multiple spaces    \n",
    "    return s \n",
    "\n",
    "syn_tokens = retrive_syn_tokens()\n",
    "rev_lookup = merge_dicts([rev_dict(x) for x in syn_tokens])  \n",
    "keys = sorted(list(set(rev_lookup.keys())),key=lambda x: -len(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "retrived: /home/yueliu/Desktop/workspace_yue/Documentation_201712/all_food_vendor__standard__20180207.p\n"
     ]
    }
   ],
   "source": [
    "\"\"\" get food names from standard food names\"\"\"\n",
    "token_path = \"/home/yueliu/Desktop/workspace_yue/Documentation_201712\"\n",
    "file_name = os.path.join(token_path,\"all_food_vendor__standard__20180207.p\")\n",
    "food_names = retrive_file(file_name)\n",
    "food_names = sorted(food_names[\"standard_name\"].unique(), key=lambda (x): -len(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of food items: 92298\n"
     ]
    }
   ],
   "source": [
    "print \"number of food items: %d\"%len(food_names1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>clean_text</th>\n",
       "      <th>loc</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>aa ahsighee bowl made with frozen aa berry pur...</td>\n",
       "      <td>[burppleinitial/review/huuB1mUX]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>aa berry bowl must try every aa bowl see on th...</td>\n",
       "      <td>[burppleinitial/review/z_Y7aErb]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                          clean_text  \\\n",
       "1  aa ahsighee bowl made with frozen aa berry pur...   \n",
       "2  aa berry bowl must try every aa bowl see on th...   \n",
       "\n",
       "                                loc  \n",
       "1  [burppleinitial/review/huuB1mUX]  \n",
       "2  [burppleinitial/review/z_Y7aErb]  "
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "samp.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 6min 9s, sys: 19min 56s, total: 26min 6s\n",
      "Wall time: 3min 18s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "samp[\"lemma_text\"] = samp[\"clean_text\"].apply(lemma_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 17.3 s, sys: 280 ms, total: 17.6 s\n",
      "Wall time: 17.3 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "samp[\"standard_text\"] = samp[\"lemma_text\"].apply(replace_token)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. check if food names are in review higher_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# search in a review, list down the possible food names (with attributes) it contain\n",
    "# longest matching food items\n",
    "def search_clean_name(searchFor):\n",
    "    searchFor= \" \" + searchFor+ \" \"\n",
    "    vs = []\n",
    "    for v in food_names:\n",
    "        if \" \" + v+ \" \" in searchFor:\n",
    "            vs.append(v)\n",
    "    v_unique = longest_unique_entity(vs)  \n",
    "    return v_unique\n",
    "\n",
    "# return \"chicken rice\" and \"fish soup\" form [\"chicken rice\", \"chicken\", \"fish soup\", \"soup\"]\n",
    "def longest_unique_entity(lst):\n",
    "    lst = list(set(lst))\n",
    "    lst1 = deepcopy(lst)\n",
    "    for i in lst:\n",
    "        for j in lst:\n",
    "            if (len(i)<len(j)) and (i in j):\n",
    "                try:\n",
    "                    lst1.remove(i)\n",
    "                except:\n",
    "                    pass\n",
    "    return tuple(lst1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 9min 20s, sys: 6.44 s, total: 9min 27s\n",
      "Wall time: 9min 20s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "samp[\"food_items\"] = samp[\"standard_text\"].apply(search_clean_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "saved: review_with_food__20180207__100.p\n"
     ]
    }
   ],
   "source": [
    "save_part_with_food(100+i, samp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>clean_text</th>\n",
       "      <th>loc</th>\n",
       "      <th>lemma_text</th>\n",
       "      <th>standard_text</th>\n",
       "      <th>food_items</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>aa ahsighee bowl made with frozen aa berry pur...</td>\n",
       "      <td>[burppleinitial/review/huuB1mUX]</td>\n",
       "      <td>aa ahsighee bowl make with frozen aa berry pur...</td>\n",
       "      <td>aa ahsighee bowl make with frozen aa berry pur...</td>\n",
       "      <td>(superfood, and, omega, pure)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>aa berry bowl must try every aa bowl see on th...</td>\n",
       "      <td>[burppleinitial/review/z_Y7aErb]</td>\n",
       "      <td>aa berry bowl must try every aa bowl see on th...</td>\n",
       "      <td>aa berry bowl must try every aa bowl see on th...</td>\n",
       "      <td>(smoothie bowl,)</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                          clean_text  \\\n",
       "1  aa ahsighee bowl made with frozen aa berry pur...   \n",
       "2  aa berry bowl must try every aa bowl see on th...   \n",
       "\n",
       "                                loc  \\\n",
       "1  [burppleinitial/review/huuB1mUX]   \n",
       "2  [burppleinitial/review/z_Y7aErb]   \n",
       "\n",
       "                                          lemma_text  \\\n",
       "1  aa ahsighee bowl make with frozen aa berry pur...   \n",
       "2  aa berry bowl must try every aa bowl see on th...   \n",
       "\n",
       "                                       standard_text  \\\n",
       "1  aa ahsighee bowl make with frozen aa berry pur...   \n",
       "2  aa berry bowl must try every aa bowl see on th...   \n",
       "\n",
       "                      food_items  \n",
       "1  (superfood, and, omega, pure)  \n",
       "2               (smoothie bowl,)  "
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "samp.head(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### process all parts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def retrive_part(i):\n",
    "    import os\n",
    "    import pickle\n",
    "    prefix = \"review\"    \n",
    "#     date_list = list(set([f.split(\"__\")[-2].replace(\".p\", \"\") \n",
    "#          for f in os.listdir(os.getcwd()) if (f.endswith(\".p\") and (prefix) in f)]))\n",
    "#     recent_date = sorted([s for s in date_list if len(s)==8])[-1]\n",
    "    recent_date = \"20180205\"\n",
    "    file_name = \"__\".join([prefix, recent_date, str(i)]) + \".p\"\n",
    "    with open(file_name, 'rb') as pfile:\n",
    "        retrived = pickle.load(pfile)       \n",
    "    print (\"retrived: %s\" % file_name)\n",
    "    print \"number of reviews: %d\"%len(retrived)\n",
    "    return retrived"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "retrived: review__20180205__1.p\n",
      "number of reviews: 10000\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "## started: 7/2/2018 1100, estimated completation time: 1800\n",
    "for i in range(1,28):\n",
    "    samp = retrive_part(i)\n",
    "    samp[\"lemma_text\"] = samp[\"clean_text\"].apply(lemma_name)\n",
    "    samp[\"standard_text\"] = samp[\"lemma_text\"].apply(replace_token)\n",
    "    samp[\"food_items\"] = samp[\"standard_text\"].apply(search_clean_name)\n",
    "    save_part_with_food(100+i, samp)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. review_with_synsets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "28\n"
     ]
    }
   ],
   "source": [
    "\"\"\"retrive parts & merge into singel df\"\"\"\n",
    "# prefix = \"review_with_food__20180205__\"\n",
    "# # all possible date when data is saved\n",
    "# file_lst = [f for f in os.listdir(os.getcwd()) if (f.endswith(\".p\") and (prefix) in f)]\n",
    "# print len(file_lst)\n",
    "\n",
    "# # retrive for testing\n",
    "# def retrive_file(file_name):\n",
    "#     import pickle\n",
    "#     with open(file_name, 'rb') as pfile:\n",
    "#         df_retrived = pickle.load(pfile)\n",
    "#     print (\"retrived: %s\" % file_name)\n",
    "#     return df_retrived\n",
    "# df_lst = [retrive_file(file_name) for file_name in file_lst]\n",
    "# df1 = pd.concat(df_lst)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from copy import deepcopy\n",
    "df1 = deepcopy(samp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 2.01 s, sys: 0 ns, total: 2.01 s\n",
      "Wall time: 2.02 s\n"
     ]
    }
   ],
   "source": [
    "%%time \n",
    "# about 5.5hrs for all reviews\n",
    "df1 = df1[df1[\"food_items\"].map(len)>0]\n",
    "col = \"food_items\"\n",
    "# split into multiple rows\n",
    "s = df1[col].apply(pd.Series, 1).stack()\n",
    "s.index = s.index.droplevel(-1)\n",
    "s.name = col \n",
    "del df1[col]\n",
    "df1 = df1.join(s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(37653, 5)\n",
      "['clean_text', 'loc', 'lemma_text', 'standard_text', 'food_items']\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>clean_text</th>\n",
       "      <th>loc</th>\n",
       "      <th>lemma_text</th>\n",
       "      <th>standard_text</th>\n",
       "      <th>food_items</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>aa ahsighee bowl made with frozen aa berry pur...</td>\n",
       "      <td>[burppleinitial/review/huuB1mUX]</td>\n",
       "      <td>aa ahsighee bowl make with frozen aa berry pur...</td>\n",
       "      <td>aa ahsighee bowl make with frozen aa berry pur...</td>\n",
       "      <td>superfood</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>aa ahsighee bowl made with frozen aa berry pur...</td>\n",
       "      <td>[burppleinitial/review/huuB1mUX]</td>\n",
       "      <td>aa ahsighee bowl make with frozen aa berry pur...</td>\n",
       "      <td>aa ahsighee bowl make with frozen aa berry pur...</td>\n",
       "      <td>and</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                          clean_text  \\\n",
       "1  aa ahsighee bowl made with frozen aa berry pur...   \n",
       "1  aa ahsighee bowl made with frozen aa berry pur...   \n",
       "\n",
       "                                loc  \\\n",
       "1  [burppleinitial/review/huuB1mUX]   \n",
       "1  [burppleinitial/review/huuB1mUX]   \n",
       "\n",
       "                                          lemma_text  \\\n",
       "1  aa ahsighee bowl make with frozen aa berry pur...   \n",
       "1  aa ahsighee bowl make with frozen aa berry pur...   \n",
       "\n",
       "                                       standard_text food_items  \n",
       "1  aa ahsighee bowl make with frozen aa berry pur...  superfood  \n",
       "1  aa ahsighee bowl make with frozen aa berry pur...        and  "
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print df1.shape\n",
    "print df1.columns.tolist()\n",
    "df1.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "saved: review_with_synsets__20180207.p\n"
     ]
    }
   ],
   "source": [
    "def save_file(df, desc):\n",
    "    import pickle\n",
    "    import datetime   \n",
    "    today = datetime.date.today()\n",
    "    today = today.strftime('%Y%m%d') \n",
    "    file_name = \"__\".join([desc, today]) + \".p\"  \n",
    "    with open(file_name, 'wb') as pfile:\n",
    "        pickle.dump(df, pfile)\n",
    "    print \"saved: %s\"%file_name\n",
    "save_file(df1, \"review_with_synsets\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluation "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(u'and', 5122),\n",
       " (u'for', 2929),\n",
       " (u'good', 1709),\n",
       " (u'food', 842),\n",
       " (u'sweet', 631),\n",
       " (u'out', 611),\n",
       " (u'flavour', 546),\n",
       " (u'sauce', 523),\n",
       " (u'singapore', 388),\n",
       " (u'back', 386),\n",
       " (u'favourite', 363),\n",
       " (u'ice cream', 353),\n",
       " (u'week', 309),\n",
       " (u'crispy', 262),\n",
       " (u'tender', 225),\n",
       " (u'egg', 216),\n",
       " (u'meat', 212),\n",
       " (u'mixed', 201),\n",
       " (u'any', 195),\n",
       " (u'choice', 176)]"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from collections import Counter\n",
    "counts = Counter(df1[\"food_items\"].tolist())\n",
    "counts.most_common(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of synsets removed: 12\n",
      "number of clean_name in reviews: 23917\n",
      "number of unique review text identified: 7504\n",
      "number of unique synset identified: 4332\n"
     ]
    }
   ],
   "source": [
    "des_key_remove = [\"and\", \"for\", \"good\", \"food\", \"out\", 'flavour', 'sauce','singapore', \n",
    "                 'back', \"any\", \"choice\", \"week\"]\n",
    "df2 = df1[~df1[\"food_items\"].isin(des_key_remove)]\n",
    "print \"number of synsets removed: %d\" % len(des_key_remove)\n",
    "print \"number of clean_name in reviews: %d\" % df2.shape[0] \n",
    "#print \"number of reviews with clean_name(s): %d\" % df2[\"loc\"].nunique()\n",
    "print \"number of unique review text identified: %d\" % df2[\"clean_text\"].nunique()\n",
    "print \"number of unique synset identified: %d\" % df2[\"food_items\"].nunique()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
