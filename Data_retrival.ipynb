{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data retrival"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20180201\n"
     ]
    }
   ],
   "source": [
    "import myfunctions as f\n",
    "print f.today()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "system_info: 2.7.14 |Anaconda custom (64-bit)| (default, Oct 27 2017, 18:21:12) \n",
      "[GCC 7.2.0]\n",
      "path_info: /home/yueliu/Desktop/workspace_yue/Documentation_201712\n",
      "{\n",
      "  \"name\" : \"star7\",\n",
      "  \"cluster_name\" : \"star\",\n",
      "  \"cluster_uuid\" : \"VDcV69ThThyb00sd6PgeMA\",\n",
      "  \"version\" : {\n",
      "    \"number\" : \"2.4.5\",\n",
      "    \"build_hash\" : \"c849dd13904f53e63e88efc33b2ceeda0b6a1276\",\n",
      "    \"build_timestamp\" : \"2017-04-24T16:18:17Z\",\n",
      "    \"build_snapshot\" : false,\n",
      "    \"lucene_version\" : \"5.5.4\"\n",
      "  },\n",
      "  \"tagline\" : \"You Know, for Search\"\n",
      "}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# python version\n",
    "import sys\n",
    "print \"system_info: %s\"%sys.version\n",
    "# current working directory\n",
    "import os\n",
    "print \"path_info: %s\"%os.getcwd() \n",
    "# setup elastic search\n",
    "f.initialise_es(1)\n",
    "foodpanda, deliveroo, wte, websites = f.delivery_para()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# To retrive food data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "doc_type = \"food\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 2h 5min 52s, sys: 8min 52s, total: 2h 14min 45s\n",
      "Wall time: 2h 15min 15s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "website = websites[0]\n",
    "f.initialise_es(0)\n",
    "website.update({\"all_rec_\"+doc_type : f.retrive_from_es(website, doc_type)})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 1h 4min 58s, sys: 2min 39s, total: 1h 7min 37s\n",
      "Wall time: 1h 8min 5s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "website = websites[1]\n",
    "f.initialise_es(0)\n",
    "website.update({\"all_rec_\"+doc_type : f.retrive_from_es(website, doc_type)})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 11min 8s, sys: 16.6 s, total: 11min 24s\n",
      "Wall time: 11min 29s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "website = websites[2]\n",
    "f.initialise_es(0)\n",
    "website.update({\"all_rec_\"+doc_type : f.retrive_from_es(website, doc_type)})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data: keep all index and dates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "### fomulate location\n",
    "def fomulate_loc(w):\n",
    "    \"\"\"formulate storage location according to es data\"\"\"\n",
    "    w['all_rec_food'][\"loc\"] = w['all_rec_food'][\"_index\"] + \"/\" + \\\n",
    "    w[\"food\"] + \"/\" + \\\n",
    "    w['all_rec_food'][\"_id\"]\n",
    "\n",
    "def fomulate_timestamp(w):\n",
    "    if w[\"_index\"] == 'what_to_eat':\n",
    "        w['all_rec_food'][\"timestamp\"] = w['all_rec_food']['_source.startTimestampGMT']\n",
    "    else:\n",
    "        d = f.retrive_from_es(w, \"crawling_cycle\")\n",
    "        cycle_time = d.set_index(w['cycle_id']).to_dict()[w['cycleStart']]\n",
    "        # remove na for food names\n",
    "        w['all_rec_food'] = w['all_rec_food'][~w['all_rec_food'][w[\"food_name\"]].isnull()]\n",
    "        # assign time according to food cycle\n",
    "        w['all_rec_food'][\"timestamp\"] = w['all_rec_food'][w['food_cycle']].apply(lambda s: cycle_time[s])\n",
    "\n",
    "def formated(w):\n",
    "    cols = [w['food_name'], w['vendor_name'], \"timestamp\", \"loc\"]\n",
    "    temp = w['all_rec_food'][cols]\n",
    "    temp.columns = [\"food_name\", \"vendor_name\",\"timestamp\", \"loc\" ]\n",
    "    temp[\"locs\"] = temp[\"timestamp\"]+ \"****\" + temp[\"loc\"]\n",
    "    temp[\"locs\"] = temp[\"locs\"].apply(lambda s: tuple(s.split(\"****\")))\n",
    "    temp = temp[[\"food_name\", \"vendor_name\", \"locs\" ]]\n",
    "    w[\"formated\"] = temp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "foodpanda:: number of records: 1764391\n",
      "deliveroo:: number of records: 1136336\n",
      "what_to_eat:: number of records: 169196\n"
     ]
    }
   ],
   "source": [
    "for w in websites:\n",
    "    fomulate_loc(w)     \n",
    "    fomulate_timestamp(w) \n",
    "    formated(w)\n",
    "    print \"%s:: number of records: %d\"%(w[\"_index\"],\n",
    "                                        w['all_rec_food'].shape[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# To save food data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "saved: foodpanda__food__20180102.p\n",
      "saved: deliveroo__food__20180102.p\n",
      "saved: what_to_eat__food__20180102.p\n"
     ]
    }
   ],
   "source": [
    "for w in websites:\n",
    "    file_name = \"__\".join([w[\"_index\"], \"food\", today]) + \".p\"\n",
    "    f.save_file(w['all_rec_food'], file_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "file_name = \"__\".join([\"all_food_vendor\", f.today()]) + \".p\"\n",
    "df1 = pd.concat([w[\"formated\"] for w in websites]) \n",
    "df = df1.groupby([\"food_name\", \"vendor_name\"])[\"locs\"].apply(list).to_frame().reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "all:: number of records: 445939\n",
      "saved: all_food_vendor__20180102.p\n"
     ]
    }
   ],
   "source": [
    "print \"all:: number of records: %d\"%(df.shape[0])\n",
    "f.save_file(df, file_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Clean the food items: get clean name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "file_name = \"all_food_vendor__20180102.p\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of drinks in drink list: 22452\n",
      "retrived: all_food_vendor__20180102.p\n",
      "Got 333575 non-drink/dessert food-vendor records\n",
      "Got 98094 unique non-drink/dessert food \n",
      "saved: all_food_vendor__clean__20180118.p\n"
     ]
    }
   ],
   "source": [
    "drink_list = f.retrive_drinks()\n",
    "df = f.retrive_file(file_name)\n",
    "df[\"clean_name\"] = df[\"food_name\"].apply(lambda s: f.clean_name_v4(s))\n",
    "\n",
    "df1 = df[~df['clean_name'].isin(drink_list)]\n",
    "print (\"Got %d non-drink/dessert food-vendor records\" % df1.shape[0])\n",
    "print (\"Got %d unique non-drink/dessert food \" % \n",
    "       df1[\"clean_name\"].nunique())\n",
    "\n",
    "file_name = \"__\".join([\"all_food_vendor\",\"clean\", f.today()]) + \".p\"\n",
    "f.save_file(df1, file_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import spacy\n",
    "nlp = spacy.load('en_core_web_sm')\n",
    "\n",
    "def lemma_name(s):\n",
    "    return \" \".join([token.lemma_ for token in nlp(unicode(s, \"utf-8\"))])\n",
    "\n",
    "df[\"lemma_name\"] = df[\"clean_name\"].apply(lambda s: lemma_name(s))\n",
    "df[\"lemma_name_2\"] = df[\"lemma_name\"].apply(lambda s: lemma_name(str(s)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There is very little difference generated by doing lemmatization twice. \n",
    "\n",
    "    positive case for lemmatization x 2: dumplings -> dumpling; dunpling -> dumpl\n",
    "    negative case : shreded -> shred -> shr \n",
    "\n",
    "Thus, we only consider doing it once."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "file_name = \"__\".join([\"all_food_vendor\",\"lemma\", f.today()]) + \".p\"\n",
    "f.save_file(df, file_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "    saved: all_food_vendor__lemma__20180122.p"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
