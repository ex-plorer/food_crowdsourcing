{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Removing words for merging food items\n",
    "\n",
    "> input: manually seletced words to remove\n",
    "\n",
    "> output: possiblely shorteded names of food items"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "system_info: 2.7.14 |Anaconda custom (64-bit)| (default, Oct 27 2017, 18:21:12) \n",
      "[GCC 7.2.0]\n",
      "path_info: /home/yueliu/Desktop/workspace_yue/Documentation_201712\n"
     ]
    }
   ],
   "source": [
    "# python version\n",
    "import sys\n",
    "print \"system_info: %s\"%sys.version\n",
    "# current working directory\n",
    "import os\n",
    "print \"path_info: %s\"%os.getcwd() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'20180305'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import myfunctions as f\n",
    "f.today()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "retrived: food_entities__20180208.p\n"
     ]
    }
   ],
   "source": [
    "## output from food synset entities\n",
    "file_name = \"food_entities__20180208.p\"\n",
    "df_retrived = f.retrive_file(file_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(92298, 11)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>food_name</th>\n",
       "      <th>locs</th>\n",
       "      <th>synonyms</th>\n",
       "      <th>menu_names</th>\n",
       "      <th>restaurant</th>\n",
       "      <th>review</th>\n",
       "      <th>review.clean_text</th>\n",
       "      <th>review.restaurant</th>\n",
       "      <th>review.text</th>\n",
       "      <th>review.image</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>food_0</td>\n",
       "      <td>-PRON- ann</td>\n",
       "      <td>[deliveroo/food/68155, deliveroo/food/AV062oM7...</td>\n",
       "      <td>[em ann]</td>\n",
       "      <td>[(Em Ann M., 3)]</td>\n",
       "      <td>[delivery_3748, delivery_3749, delivery_3750]</td>\n",
       "      <td>[burppleinitial/review/vGui2G8q]</td>\n",
       "      <td>[maggie mee goreng from the rooftop at screeni...</td>\n",
       "      <td>[(burpple_12581, 1)]</td>\n",
       "      <td>[Maggi Mee Goreng from The Rooftop at Screenin...</td>\n",
       "      <td>[vGui2G8q]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>food_1</td>\n",
       "      <td>-PRON- bai vege</td>\n",
       "      <td>[foodpanda/menu_item/AV44Ejd8W4PLiMnQOaiu, foo...</td>\n",
       "      <td>[you bai vege]</td>\n",
       "      <td>[(H6. You Bai Vege, 2)]</td>\n",
       "      <td>[delivery_221, delivery_222]</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    index        food_name                                               locs  \\\n",
       "0  food_0       -PRON- ann  [deliveroo/food/68155, deliveroo/food/AV062oM7...   \n",
       "1  food_1  -PRON- bai vege  [foodpanda/menu_item/AV44Ejd8W4PLiMnQOaiu, foo...   \n",
       "\n",
       "         synonyms               menu_names  \\\n",
       "0        [em ann]         [(Em Ann M., 3)]   \n",
       "1  [you bai vege]  [(H6. You Bai Vege, 2)]   \n",
       "\n",
       "                                      restaurant  \\\n",
       "0  [delivery_3748, delivery_3749, delivery_3750]   \n",
       "1                   [delivery_221, delivery_222]   \n",
       "\n",
       "                             review  \\\n",
       "0  [burppleinitial/review/vGui2G8q]   \n",
       "1                               NaN   \n",
       "\n",
       "                                   review.clean_text     review.restaurant  \\\n",
       "0  [maggie mee goreng from the rooftop at screeni...  [(burpple_12581, 1)]   \n",
       "1                                                NaN                   NaN   \n",
       "\n",
       "                                         review.text review.image  \n",
       "0  [Maggi Mee Goreng from The Rooftop at Screenin...   [vGui2G8q]  \n",
       "1                                                NaN          NaN  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print df_retrived.shape\n",
    "df_retrived.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "food_names = df_retrived[\"food_name\"].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# count frequency of occurance of the unigram tokens\n",
    "tokens = [s.split() for s in food_names]\n",
    "from collections import Counter\n",
    "c = Counter([item for sublist in tokens for item in sublist])\n",
    "count_tokens = sorted(c.items(), key=lambda x: -x[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(u'with', 16061),\n",
       " (u'chicken', 11072),\n",
       " (u'fry', 8164),\n",
       " (u'rice', 6989),\n",
       " (u'and', 6657)]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "count_tokens[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of uinique tokens: 14644\n"
     ]
    }
   ],
   "source": [
    "# all tokens\n",
    "unique_tokens = [s[0] for s in count_tokens]\n",
    "print \"number of uinique tokens: %d\"%len(unique_tokens)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Checking the words to be removed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of words to remove: 400\n"
     ]
    }
   ],
   "source": [
    "# import file with possible error\n",
    "file_name = \"clean_food_remove_words.csv\"\n",
    "import pandas as pd\n",
    "rmv = pd.read_csv(file_name, header=None)[0].tolist()\n",
    "print \"number of words to remove: %d\"%len(rmv) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of unigram words possible to remove: 248\n"
     ]
    }
   ],
   "source": [
    "# select only unigram rmv\n",
    "rmv_uni = [s for s in rmv if len(s.split())==1]\n",
    "in_token = [s for s in rmv_uni if s in unique_tokens]\n",
    "# lemma form to match against cleaned names\n",
    "out_token = [s for s in rmv_uni if s not in unique_tokens]\n",
    "import spacy\n",
    "nlp = spacy.load('en_core_web_sm')\n",
    "def lemma_name(s):\n",
    "    return \" \".join([token.lemma_ for token in nlp(unicode(s, \"utf-8\"))])\n",
    "out_token_lemma = [lemma_name(f.clean_name_v4(s)) for s in out_token]\n",
    "in_token_lemma = [s for s in out_token_lemma if s in unique_tokens]\n",
    "# all uni-gram tokens sorted by frequency of occurance in food names\n",
    "rmv_uni = in_token + in_token_lemma\n",
    "rmv_uni = [s for s in unique_tokens if s in rmv_uni]\n",
    "print \"number of unigram words possible to remove: %d\"%len(rmv_uni)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[u'with', u'and', u'sauce', u'set', u'spicy', u'grill', u'slice']"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rmv_uni[:7]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of multigram words to be removed: 46\n"
     ]
    }
   ],
   "source": [
    "rmv_multi = [s for s in rmv_new if len(s.split())>1]\n",
    "# lemma form to match against cleaned names\n",
    "import spacy\n",
    "nlp = spacy.load('en_core_web_sm')\n",
    "def lemma_name(s):\n",
    "    return \" \".join([token.lemma_ for token in nlp(unicode(s, \"utf-8\"))])\n",
    "rmv_multi_lemma = [lemma_name(f.clean_name_v4(s)) for s in rmv_multi]\n",
    "rmv_multi = sorted(list(set(rmv_multi_lemma + rmv_multi)))\n",
    "# check if they are contained in some food names\n",
    "in_multi_token = []\n",
    "for s1 in sorted(list(set(food_names))):\n",
    "    s1 = \" \" + s1 + \" \"\n",
    "    for s2 in rmv_multi:\n",
    "        if \" \" + s2 + \" \" in s1:\n",
    "            in_multi_token.append(s2)\n",
    "# check if they are composed of single removavble tokens \n",
    "rmv_multi_tmp = set(in_multi_token)\n",
    "rmv_multi = []\n",
    "for s in rmv_multi_tmp:\n",
    "    if len(set(s.split()) | set(rmv_uni)) > len(set(rmv_uni)):\n",
    "        rmv_multi.append(s)\n",
    "print \"number of multigram words to be removed: %d\"%len(rmv_multi)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[u'duo of', u'the ugly', u'cup of', 'stir fried', u'piece of', u'monday blue']"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rmv_multi[:6]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of words to remove: 292\n"
     ]
    }
   ],
   "source": [
    "wrongly_rmv = [\"stir fry\", 'stir fried']\n",
    "rmv = rmv_uni + rmv_multi\n",
    "rmv = [s for s in rmv if s not in wrongly_rmv]\n",
    "print \"number of words to remove: %d\"%len(rmv) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "retrived: words_to_remove_20180305.csv\n"
     ]
    }
   ],
   "source": [
    "# save the file back to words to remove\n",
    "file_name = \"words_to_remove_\" + f.today() + \".csv\"\n",
    "import csv\n",
    "with open(file_name, \"w\") as output:\n",
    "    writer = csv.writer(output, lineterminator='\\n')\n",
    "    for val in rmv:\n",
    "        writer.writerow([val])  \n",
    "print (\"retrived: %s\" % file_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## shorten food name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from copy import deepcopy\n",
    "df = deepcopy(df_retrived)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of words to remove: 292\n"
     ]
    }
   ],
   "source": [
    "# import file, longer words first\n",
    "file_name = \"words_to_remove_20180305.csv\"\n",
    "import pandas as pd\n",
    "rmv = pd.read_csv(file_name, header=None)[0].tolist()\n",
    "rmv.sort(key=lambda item: (-len(item), item))\n",
    "print \"number of words to remove: %d\"%len(rmv)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def shorten_name(name):\n",
    "    name = \" \" + name + \" \"\n",
    "    for s in rmv:\n",
    "        if \" \" + s + \" \" in name:\n",
    "            name = name.replace(\" \" + s + \" \", \" \")\n",
    "    return name.strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 6.4 s, sys: 72 ms, total: 6.47 s\n",
      "Wall time: 6.39 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "df[\"short_name\"] = df[\"food_name\"].apply(shorten_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>food_name</th>\n",
       "      <th>locs</th>\n",
       "      <th>synonyms</th>\n",
       "      <th>menu_names</th>\n",
       "      <th>restaurant</th>\n",
       "      <th>review</th>\n",
       "      <th>review.clean_text</th>\n",
       "      <th>review.restaurant</th>\n",
       "      <th>review.text</th>\n",
       "      <th>review.image</th>\n",
       "      <th>short_name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>food_0</td>\n",
       "      <td>-PRON- ann</td>\n",
       "      <td>[deliveroo/food/68155, deliveroo/food/AV062oM7...</td>\n",
       "      <td>[em ann]</td>\n",
       "      <td>[(Em Ann M., 3)]</td>\n",
       "      <td>[delivery_3748, delivery_3749, delivery_3750]</td>\n",
       "      <td>[burppleinitial/review/vGui2G8q]</td>\n",
       "      <td>[maggie mee goreng from the rooftop at screeni...</td>\n",
       "      <td>[(burpple_12581, 1)]</td>\n",
       "      <td>[Maggi Mee Goreng from The Rooftop at Screenin...</td>\n",
       "      <td>[vGui2G8q]</td>\n",
       "      <td>-PRON- ann</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>food_1</td>\n",
       "      <td>-PRON- bai vege</td>\n",
       "      <td>[foodpanda/menu_item/AV44Ejd8W4PLiMnQOaiu, foo...</td>\n",
       "      <td>[you bai vege]</td>\n",
       "      <td>[(H6. You Bai Vege, 2)]</td>\n",
       "      <td>[delivery_221, delivery_222]</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-PRON- bai vege</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    index        food_name                                               locs  \\\n",
       "0  food_0       -PRON- ann  [deliveroo/food/68155, deliveroo/food/AV062oM7...   \n",
       "1  food_1  -PRON- bai vege  [foodpanda/menu_item/AV44Ejd8W4PLiMnQOaiu, foo...   \n",
       "\n",
       "         synonyms               menu_names  \\\n",
       "0        [em ann]         [(Em Ann M., 3)]   \n",
       "1  [you bai vege]  [(H6. You Bai Vege, 2)]   \n",
       "\n",
       "                                      restaurant  \\\n",
       "0  [delivery_3748, delivery_3749, delivery_3750]   \n",
       "1                   [delivery_221, delivery_222]   \n",
       "\n",
       "                             review  \\\n",
       "0  [burppleinitial/review/vGui2G8q]   \n",
       "1                               NaN   \n",
       "\n",
       "                                   review.clean_text     review.restaurant  \\\n",
       "0  [maggie mee goreng from the rooftop at screeni...  [(burpple_12581, 1)]   \n",
       "1                                                NaN                   NaN   \n",
       "\n",
       "                                         review.text review.image  \\\n",
       "0  [Maggi Mee Goreng from The Rooftop at Screenin...   [vGui2G8q]   \n",
       "1                                                NaN          NaN   \n",
       "\n",
       "        short_name  \n",
       "0       -PRON- ann  \n",
       "1  -PRON- bai vege  "
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "75908"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[\"short_name\"].nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(92298, 12)"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "=> name shortening works, but need to check the merged records"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
