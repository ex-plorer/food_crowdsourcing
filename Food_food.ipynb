{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Food-food edges\n",
    "Similarities based on word2vec embeddings for food description. Also possible for Burpple review text, but not shown here.\n",
    "> ... terms in the food2vec vocabulary. \n",
    "\n",
    "> ... food pairs with sim > 0.95"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "system_info: 2.7.14 |Anaconda custom (64-bit)| (default, Oct 27 2017, 18:21:12) \n",
      "[GCC 7.2.0]\n",
      "path_info: /home/yueliu/Desktop/workspace_yue/Documentation_201712\n"
     ]
    }
   ],
   "source": [
    "# python version\n",
    "import sys\n",
    "print \"system_info: %s\"%sys.version\n",
    "# current working directory\n",
    "import os\n",
    "print \"path_info: %s\"%os.getcwd() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'20180208'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import myfunctions as f\n",
    "f.today()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "retrived: foodpanda__food__20180102.p\n",
      "retrived: deliveroo__food__20180102.p\n",
      "retrived: what_to_eat__food__20180102.p\n",
      "CPU times: user 5min 22s, sys: 9.5 s, total: 5min 32s\n",
      "Wall time: 5min 33s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "loc_decs_ref = dict()\n",
    "for website in websites:\n",
    "    file_name = website[\"_index\"]+ \"__food__20180102.p\"  \n",
    "    df_retrived = f.retrive_file(file_name)\n",
    "    loc_decs_ref.update(df_retrived.set_index(\"loc\").to_dict()[\"_source.description\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3069923\n"
     ]
    }
   ],
   "source": [
    "print len(loc_decs_ref)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# get desc: loc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "retrived: food_entities__20180208.p\n"
     ]
    }
   ],
   "source": [
    "file_name = \"food_entities__20180208.p\"\n",
    "food_entities = f.retrive_file(file_name)\n",
    "food_loc_ref = food_entities.set_index(\"index\").to_dict()[\"locs\"]\n",
    "# loc_food_ref =  {}\n",
    "# for k,v in food_loc_ref.items():\n",
    "#     for x in v:\n",
    "#         loc_food_ref.setdefault(x,[]).append(k)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "92298\n"
     ]
    }
   ],
   "source": [
    "print len(food_loc_ref)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(92298, 3)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>locs</th>\n",
       "      <th>desc</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>food_28136</td>\n",
       "      <td>[foodpanda/menu_item/110873, foodpanda/menu_it...</td>\n",
       "      <td>[Mixed seed parsley garlic butter, Mixed seed ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>food_69958</td>\n",
       "      <td>[foodpanda/menu_item/106972, deliveroo/food/12...</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        index                                               locs  \\\n",
       "0  food_28136  [foodpanda/menu_item/110873, foodpanda/menu_it...   \n",
       "1  food_69958  [foodpanda/menu_item/106972, deliveroo/food/12...   \n",
       "\n",
       "                                                desc  \n",
       "0  [Mixed seed parsley garlic butter, Mixed seed ...  \n",
       "1                                                 []  "
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "food_descs = pd.DataFrame(food_loc_ref.items(), columns=['index', 'locs']) \n",
    "food_descs[\"desc\"] = food_descs[\"locs\"].apply(lambda lst: [loc_decs_ref[l] for l in lst]) \n",
    "##removing nan\n",
    "food_descs[\"desc\"] = food_descs[\"desc\"].apply(lambda lst: [l for l in lst if l==l]) \n",
    "print food_descs.shape\n",
    "food_descs.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\"\"\" from food_descptions, generate embeddings \"\"\"\n",
    "from gensim.models import Word2Vec\n",
    "sentences =  [item for sublist in food_descs[\"desc\"].tolist() for item in sublist]\n",
    "sentences = [l.split() for l in sentences]\n",
    "word2vec_filepath = os.path.join(os.getcwd(), 'word2vec_model')\n",
    "# initiate the model and perform the first epoch of training\n",
    "food2vec = Word2Vec(sentences, size=100, window=5, min_count=5, sg=1, workers=4)\n",
    "food2vec.save(word2vec_filepath)\n",
    "# perform another 11 epochs of training\n",
    "for i in range(1,12):\n",
    "    food2vec.train(sentences)\n",
    "    food2vec.save(word2vec_filepath)\n",
    "# load the finished model from disk\n",
    "food2vec = Word2Vec.load(word2vec_filepath)\n",
    "food2vec.init_sims()\n",
    "\n",
    "print u'{} training epochs so far.'.format(food2vec.train_count)\n",
    "print u'{:,} terms in the food2vec vocabulary.'.format(len(food2vec.vocab))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# build a list of the terms, integer indices,\n",
    "# and term counts from the food2vec model vocabulary\n",
    "import pandas as pd\n",
    "ordered_vocab = [(term, voc.index, voc.count)\n",
    "                 for term, voc in food2vec.vocab.iteritems()]\n",
    "# sort by the term counts, so the most common terms appear first\n",
    "ordered_vocab = sorted(ordered_vocab, key=lambda (term, index, count): -count)\n",
    "# unzip the terms, integer indices, and counts into separate lists\n",
    "ordered_terms, term_indices, term_counts = zip(*ordered_vocab)\n",
    "# create a DataFrame with the food2vec vectors as data,\n",
    "# and the terms as row labels\n",
    "word_vectors = pd.DataFrame(food2vec.syn0norm[term_indices, :],\n",
    "                            index=ordered_terms)\n",
    "print word_vectors.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_related_terms(token, topn=10):\n",
    "    \"\"\"\n",
    "    look up the topn most similar terms to token and print them as a formatted list\n",
    "    \"\"\"\n",
    "    for word, similarity in food2vec.most_similar(positive=[token], \n",
    "                                                  topn=topn):\n",
    "        print u'{:20} {}'.format(word, round(similarity, 3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s = \"fried\"\n",
    "print s\n",
    "print get_related_terms(s)\n",
    "print \"\\n\"\n",
    "s = \"chicken\"\n",
    "print s\n",
    "print get_related_terms(s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "## using weighted average\n",
    "import numpy as np\n",
    "vocab = word_vectors.index.tolist()\n",
    "m = word_vectors.as_matrix()\n",
    "\n",
    "def find_weight(values, w):\n",
    "    if w in values.keys():\n",
    "        return values[w]\n",
    "    return 0\n",
    "def desc_embedding(lst):\n",
    "    words = str(\" \".join(lst)).split(\" \")\n",
    "    values = reduce( lambda d, c: d.update([(c, d.get(c,0)+1)]) or d, words, {})\n",
    "    weights = [find_weight(values, w) for w in vocab]\n",
    "    try:\n",
    "        return np.average(m, axis = 0, weights = weights)\n",
    "    except:\n",
    "        \"\"\" ZeroDivisionError: Weights sum to zero, can't be normalized \"\"\"\n",
    "        return np.average(m, axis = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "food_descs[\"text_vector\"] = food_descs[\"desc\"].apply(desc_embedding)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "text_vectors = food_descs.set_index(\"index\").to_dict()[\"text_vector\"]\n",
    "\n",
    "def compute_sim(v1, v2):\n",
    "    from sklearn.metrics.pairwise import cosine_similarity\n",
    "    return cosine_similarity([v1], [v2])[0][0]\n",
    "def find_most_similar(v1, topn=10):\n",
    "    sim_lst = []\n",
    "    for v in names_vectors.keys():\n",
    "        sim_lst.append((v, compute_sim(names_vectors[v1], names_vectors[v])))\n",
    "    sim_lst.sort(key=lambda tup: tup[1], reverse=True) \n",
    "    return sim_lst[1:topn+1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## find all sim\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "lst = food_descs[\"text_vector\"].tolist()\n",
    "sims = cosine_similarity(lst)\n",
    "## convert to df\n",
    "import pandas as pd\n",
    "df_sims = pd.DataFrame(sims, index=food_descs[\"index\"], columns=food_descs[\"index\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "treshold = 0.95\n",
    "high_sim = []\n",
    "names = food_descs[\"index\"].tolist()\n",
    "for i in range(len(lst)):\n",
    "    for k in range(i+1, len(lst)):\n",
    "        if sims[i][k]> treshold and sims[i][k]<0.999999999999999:\n",
    "            high_sim.append((names[i], names[k], sims[i][k]))  \n",
    "print len(high_sim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sample\n",
    "high_sim[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "ff_desc_sim = []\n",
    "relation_type = \"ff_desc_sim\"\n",
    "index = 0\n",
    "for triplet in high_sim:\n",
    "    ff_desc_sim.append([index, triplet[0], triplet[2], triplet[1], relation_type])\n",
    "    index+=1\n",
    "    ff_desc_sim.append([index, triplet[1], triplet[2], triplet[0], relation_type])\n",
    "    index+=1\n",
    "print \"number of ff_desc_sim relations found: %d\"%index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "file_name = \"__\".join([\"ff_desc_sim\", f.today()]) + \".p\"\n",
    "f.save_file(ff_desc_sim, file_name)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
