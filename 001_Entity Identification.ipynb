{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data retrival"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'20180314'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "import myfunctions as f\n",
    "f.today()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "system_info: 2.7.14 |Anaconda custom (64-bit)| (default, Oct 27 2017, 18:21:12) \n",
      "[GCC 7.2.0]\n",
      "path_info: /home/yueliu/Desktop/workspace_yue/Documentation_201712\n"
     ]
    }
   ],
   "source": [
    "# python version\n",
    "import sys\n",
    "print \"system_info: %s\"%sys.version\n",
    "# current working directory\n",
    "import os\n",
    "print \"path_info: %s\"%os.getcwd() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "  \"name\" : \"star7\",\n",
      "  \"cluster_name\" : \"star\",\n",
      "  \"cluster_uuid\" : \"VDcV69ThThyb00sd6PgeMA\",\n",
      "  \"version\" : {\n",
      "    \"number\" : \"2.4.5\",\n",
      "    \"build_hash\" : \"c849dd13904f53e63e88efc33b2ceeda0b6a1276\",\n",
      "    \"build_timestamp\" : \"2017-04-24T16:18:17Z\",\n",
      "    \"build_snapshot\" : false,\n",
      "    \"lucene_version\" : \"5.5.4\"\n",
      "  },\n",
      "  \"tagline\" : \"You Know, for Search\"\n",
      "}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# setup elastic search\n",
    "f.initialise_es(1)\n",
    "foodpanda, deliveroo, wte, websites = f.delivery_para()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# To retrive food data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "doc_type = \"food\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 2h 32min 15s, sys: 10min 4s, total: 2h 42min 20s\n",
      "Wall time: 2h 43min 3s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "website = websites[0]\n",
    "f.initialise_es(0)\n",
    "website.update({\"all_rec_\"+doc_type : f.retrive_from_es(website, doc_type)})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 1h 31min 17s, sys: 5min 15s, total: 1h 36min 32s\n",
      "Wall time: 1h 37min 16s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "website = websites[1]\n",
    "f.initialise_es(0)\n",
    "website.update({\"all_rec_\"+doc_type : f.retrive_from_es(website, doc_type)})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 14min 50s, sys: 30.9 s, total: 15min 21s\n",
      "Wall time: 15min 27s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "website = websites[2]\n",
    "f.initialise_es(0)\n",
    "website.update({\"all_rec_\"+doc_type : f.retrive_from_es(website, doc_type)})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data: keep all index and dates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "### fomulate location\n",
    "def fomulate_loc(w):\n",
    "    \"\"\"formulate storage location according to es data\"\"\"\n",
    "    w['all_rec_food'][\"loc\"] = w['all_rec_food'][\"_index\"] + \"/\" + \\\n",
    "    w[\"food\"] + \"/\" + \\\n",
    "    w['all_rec_food'][\"_id\"]\n",
    "\n",
    "def fomulate_timestamp(w):\n",
    "    if w[\"_index\"] == 'what_to_eat':\n",
    "        w['all_rec_food'][\"timestamp\"] = w['all_rec_food']['_source.startTimestampGMT']\n",
    "    else:\n",
    "        d = f.retrive_from_es(w, \"crawling_cycle\")\n",
    "        cycle_time = d.set_index(w['cycle_id']).to_dict()[w['cycleStart']]\n",
    "        # remove na for food names\n",
    "        w['all_rec_food'] = w['all_rec_food'][~w['all_rec_food'][w[\"food_name\"]].isnull()]\n",
    "        # assign time according to food cycle\n",
    "        w['all_rec_food'][\"timestamp\"] = w['all_rec_food'][w['food_cycle']].apply(lambda s: cycle_time[s])\n",
    "\n",
    "def formated(w):\n",
    "    cols = [w['food_name'], w['vendor_name'], \"timestamp\", \"loc\"]\n",
    "    temp = w['all_rec_food'][cols]\n",
    "    temp.columns = [\"food_name\", \"vendor_name\",\"timestamp\", \"loc\" ]\n",
    "    temp[\"locs\"] = temp[\"timestamp\"]+ \"****\" + temp[\"loc\"]\n",
    "    temp[\"locs\"] = temp[\"locs\"].apply(lambda s: tuple(s.split(\"****\")))\n",
    "    temp = temp[[\"food_name\", \"vendor_name\", \"locs\" ]]\n",
    "    w[\"formated\"] = temp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "foodpanda:: number of records: 2032443\n",
      "deliveroo:: number of records: 1459312\n",
      "what_to_eat:: number of records: 226512\n"
     ]
    }
   ],
   "source": [
    "for w in websites:\n",
    "    fomulate_loc(w)     \n",
    "    fomulate_timestamp(w) \n",
    "    formated(w)\n",
    "    print \"%s:: number of records: %d\"%(w[\"_index\"],\n",
    "                                        w['all_rec_food'].shape[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# To save food data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "saved: foodpanda__food__20180314.p\n",
      "saved: deliveroo__food__20180314.p\n",
      "saved: what_to_eat__food__20180314.p\n"
     ]
    }
   ],
   "source": [
    "for w in websites:\n",
    "    file_name = \"__\".join([w[\"_index\"], \"food\", f.today()]) + \".p\"\n",
    "    f.save_file(w['all_rec_food'], file_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "foodpanda, deliveroo, wte, websites = f.delivery_para()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "retrived: foodpanda__food__20180314.p\n",
      "retrived: deliveroo__food__20180314.p\n",
      "retrived: what_to_eat__food__20180314.p\n"
     ]
    }
   ],
   "source": [
    "df_lst = []\n",
    "for w in websites:\n",
    "    file_name = \"__\".join([w[\"_index\"], \"food\", f.today()]) + \".p\"\n",
    "    df_lst.append(f.retrive_file(file_name))\n",
    "import pandas as pd\n",
    "df1 = pd.concat(df_lst) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "df = df1.groupby([\"food_name\", \"vendor_name\"])[\"locs\"].apply(\n",
    "    list).to_frame().reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "all:: number of records: 491732\n",
      "saved: all_food_vendor__20180314.p\n"
     ]
    }
   ],
   "source": [
    "print \"all:: number of records: %d\"%(df.shape[0])\n",
    "file_name = \"__\".join([\"all_food_vendor\", f.today()]) + \".p\"\n",
    "f.save_file(df, file_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Clean the food items: get clean name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "retrived: all_food_vendor__20180314.p\n"
     ]
    }
   ],
   "source": [
    "file_name = \"all_food_vendor__20180314.p\"\n",
    "df = f.retrive_file(file_name)\n",
    "df[\"clean_name\"] = df[\"food_name\"].apply(lambda s: f.clean_name_v2(s))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>food_name</th>\n",
       "      <th>vendor_name</th>\n",
       "      <th>locs</th>\n",
       "      <th>clean_name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>362606</th>\n",
       "      <td>Preserved Radish Bean Curd</td>\n",
       "      <td>The One Place - Eunos</td>\n",
       "      <td>[(2017-07-03T17:55:01.668428, deliveroo/food/4...</td>\n",
       "      <td>preserved radish bean curd</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>108552</th>\n",
       "      <td>Brownie (Slice)</td>\n",
       "      <td>Island Creamery - Joo Chiat</td>\n",
       "      <td>[(2017-07-03T17:55:01.668428, deliveroo/food/6...</td>\n",
       "      <td>brownie slice</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                         food_name                  vendor_name  \\\n",
       "362606  Preserved Radish Bean Curd        The One Place - Eunos   \n",
       "108552             Brownie (Slice)  Island Creamery - Joo Chiat   \n",
       "\n",
       "                                                     locs  \\\n",
       "362606  [(2017-07-03T17:55:01.668428, deliveroo/food/4...   \n",
       "108552  [(2017-07-03T17:55:01.668428, deliveroo/food/6...   \n",
       "\n",
       "                        clean_name  \n",
       "362606  preserved radish bean curd  \n",
       "108552               brownie slice  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.sample(2, random_state=2008)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "saved: all_food_vendor__clean__20180315.p\n"
     ]
    }
   ],
   "source": [
    "file_name = \"__\".join([\"all_food_vendor\",\"clean\", f.today()]) + \".p\"\n",
    "f.save_file(df, file_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "saved: entity_identification_test_case_20180315.csv\n"
     ]
    }
   ],
   "source": [
    "# save test case to csv\n",
    "file_name = \"entity_identification_test_case_\" + f.today()+\".csv\"\n",
    "df.sample(100, random_state=2008)[[\"food_name\", \"clean_name\"]].to_csv(file_name, \n",
    "                                                                     index=False)\n",
    "print \"saved: %s\"%file_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of unique food items: 139779\n",
      "saved: food_items_20180315.csv\n"
     ]
    }
   ],
   "source": [
    "# save a version of all food names\n",
    "food_names = sorted([s for s in set(df[\"clean_name\"].tolist()) if (s!=\"\" and s==s)])\n",
    "print \"number of unique food items: %d\"%len(food_names)\n",
    "\n",
    "file_name = \"food_items_\" + f.today() + \".csv\"\n",
    "import csv\n",
    "with open(file_name, \"w\") as output:\n",
    "    writer = csv.writer(output, lineterminator='\\n')\n",
    "    for val in food_names:\n",
    "        writer.writerow([val])  \n",
    "print (\"saved: %s\" % file_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
