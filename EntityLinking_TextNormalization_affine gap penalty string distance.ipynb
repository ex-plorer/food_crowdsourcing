{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## affine gap penalty string distance\n",
    "\n",
    "> input: food names\n",
    "\n",
    "> output: words to remove / synomyms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "system_info: 2.7.14 |Anaconda custom (64-bit)| (default, Oct 27 2017, 18:21:12) \n",
      "[GCC 7.2.0]\n",
      "path_info: /home/yueliu/Desktop/workspace_yue/Documentation_201712\n"
     ]
    }
   ],
   "source": [
    "# python version\n",
    "import sys\n",
    "print \"system_info: %s\"%sys.version\n",
    "# current working directory\n",
    "import os\n",
    "print \"path_info: %s\"%os.getcwd() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'20180309'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "import myfunctions as f\n",
    "f.today()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "retrived: food_entities__20180308.p\n"
     ]
    }
   ],
   "source": [
    "## output from food synset entities\n",
    "file_name = \"food_entities__20180308.p\"\n",
    "df_retrived = f.retrive_file(file_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(92298, 12)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>food_name</th>\n",
       "      <th>locs</th>\n",
       "      <th>synonyms</th>\n",
       "      <th>menu_names</th>\n",
       "      <th>restaurant</th>\n",
       "      <th>review</th>\n",
       "      <th>review.clean_text</th>\n",
       "      <th>review.restaurant</th>\n",
       "      <th>review.text</th>\n",
       "      <th>review.image</th>\n",
       "      <th>short_name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>food_0</td>\n",
       "      <td>-PRON- ann</td>\n",
       "      <td>[deliveroo/food/68155, deliveroo/food/AV062oM7...</td>\n",
       "      <td>[em ann]</td>\n",
       "      <td>[(Em Ann M., 3)]</td>\n",
       "      <td>[delivery_3748, delivery_3749, delivery_3750]</td>\n",
       "      <td>[burppleinitial/review/vGui2G8q]</td>\n",
       "      <td>[maggie mee goreng from the rooftop at screeni...</td>\n",
       "      <td>[(burpple_12581, 1)]</td>\n",
       "      <td>[Maggi Mee Goreng from The Rooftop at Screenin...</td>\n",
       "      <td>[vGui2G8q]</td>\n",
       "      <td>-PRON- ann</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>food_1</td>\n",
       "      <td>-PRON- bai vege</td>\n",
       "      <td>[foodpanda/menu_item/AV44Ejd8W4PLiMnQOaiu, foo...</td>\n",
       "      <td>[you bai vege]</td>\n",
       "      <td>[(H6. You Bai Vege, 2)]</td>\n",
       "      <td>[delivery_221, delivery_222]</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-PRON- bai vege</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    index        food_name                                               locs  \\\n",
       "0  food_0       -PRON- ann  [deliveroo/food/68155, deliveroo/food/AV062oM7...   \n",
       "1  food_1  -PRON- bai vege  [foodpanda/menu_item/AV44Ejd8W4PLiMnQOaiu, foo...   \n",
       "\n",
       "         synonyms               menu_names  \\\n",
       "0        [em ann]         [(Em Ann M., 3)]   \n",
       "1  [you bai vege]  [(H6. You Bai Vege, 2)]   \n",
       "\n",
       "                                      restaurant  \\\n",
       "0  [delivery_3748, delivery_3749, delivery_3750]   \n",
       "1                   [delivery_221, delivery_222]   \n",
       "\n",
       "                             review  \\\n",
       "0  [burppleinitial/review/vGui2G8q]   \n",
       "1                               NaN   \n",
       "\n",
       "                                   review.clean_text     review.restaurant  \\\n",
       "0  [maggie mee goreng from the rooftop at screeni...  [(burpple_12581, 1)]   \n",
       "1                                                NaN                   NaN   \n",
       "\n",
       "                                         review.text review.image  \\\n",
       "0  [Maggi Mee Goreng from The Rooftop at Screenin...   [vGui2G8q]   \n",
       "1                                                NaN          NaN   \n",
       "\n",
       "        short_name  \n",
       "0       -PRON- ann  \n",
       "1  -PRON- bai vege  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print df_retrived.shape\n",
    "df_retrived.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "92077\n"
     ]
    }
   ],
   "source": [
    "# food names without drinks\n",
    "food_names = df_retrived[\"food_name\"].tolist()\n",
    "\n",
    "import pandas as pd \n",
    "try:\n",
    "    file_name = \"drink_20180308.csv\"\n",
    "    drink_lst = pd.read_csv(file_name, header=None)[0].tolist()\n",
    "except:\n",
    "    drinl_lst = []\n",
    "drink_lst = [\"\"] + drink_lst\n",
    "\n",
    "food_names = [s for s in sorted(list(set(food_names))) if s not in drink_lst]\n",
    "print len(food_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(u'with', 16055),\n",
       " (u'chicken', 11071),\n",
       " (u'fry', 8164),\n",
       " (u'rice', 6981),\n",
       " (u'and', 6641)]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# count frequency of occurance of the unigram tokens\n",
    "tokens = [s.split() for s in food_names]\n",
    "from collections import Counter\n",
    "c = Counter([item for sublist in tokens for item in sublist])\n",
    "count_tokens = sorted(c.items(), key=lambda x: -x[1])\n",
    "count_tokens[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of uinique tokens: 14603\n"
     ]
    }
   ],
   "source": [
    "# all tokens\n",
    "unique_tokens = [s[0] for s in count_tokens]\n",
    "print \"number of uinique tokens: %d\"%len(unique_tokens)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Use affine gap penalty string distance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "33.0 33.0 5.5\n"
     ]
    }
   ],
   "source": [
    "# example \n",
    "import affinegap\n",
    "d1 = affinegap.affineGapDistance('foo', 'bar')\n",
    "d2 = affinegap.affineGapDistance('foo', 'bar',\n",
    "                                 matchWeight = 1,\n",
    "                                 mismatchWeight = 11,\n",
    "                                 gapWeight = 10,\n",
    "                                 spaceWeight = 7,\n",
    "                                 abbreviation_scale = .125)\n",
    "d3 = affinegap.normalizedAffineGapDistance('foo', 'bar')\n",
    "\n",
    "print d1, d2, d3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[u'absolutely mango yogurt cake',\n",
       " u'abundance',\n",
       " u'abura soba',\n",
       " u'aburasoba',\n",
       " u'aburi akami maguro',\n",
       " u'aburi bara chirashi',\n",
       " u'aburi bara chirashi don set',\n",
       " u'aburi broccoli',\n",
       " u'aburi cha shu',\n",
       " u'aburi chicken raman']"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample_names = food_names[140:150]\n",
    "sample_names "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sample_dist = []\n",
    "sample_dist_norm = []\n",
    "import itertools\n",
    "for s0, s1 in itertools.combinations(sample_names,2):\n",
    "    sample_dist.append([affinegap.affineGapDistance(s0, s1), s0, s1])\n",
    "    sample_dist_norm.append([affinegap.normalizedAffineGapDistance(s0, s1), s0, s1]) \n",
    "sample_dist = sorted(sample_dist, key=lambda x: x[0])\n",
    "sample_dist_norm = sorted(sample_dist_norm, key=lambda x: x[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[26.0, u'abura soba', u'aburasoba'],\n",
       " [27.25, u'aburi bara chirashi', u'aburi bara chirashi don set'],\n",
       " [53.75, u'aburasoba', u'aburi cha shu'],\n",
       " [58.125, u'aburasoba', u'aburi akami maguro'],\n",
       " [59.125, u'abura soba', u'aburi bara chirashi']]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample_dist[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[0.592391312122345, u'aburi bara chirashi', u'aburi bara chirashi don set'],\n",
       " [1.3684210777282715, u'abura soba', u'aburasoba'],\n",
       " [1.787162184715271, u'abura soba', u'aburi bara chirashi don set'],\n",
       " [2.0387930870056152, u'abura soba', u'aburi bara chirashi'],\n",
       " [2.0487804412841797, u'aburi bara chirashi don set', u'aburi broccoli']]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample_dist_norm[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dist pairs: 499500\n",
      "dist smaller than threshold=1: 509\n",
      "CPU times: user 3.77 s, sys: 176 ms, total: 3.94 s\n",
      "Wall time: 3.75 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# to estimate the total time\n",
    "dist_norm = []\n",
    "import itertools\n",
    "for s0, s1 in itertools.combinations(food_names[1000:2000],2):\n",
    "    try:\n",
    "        d = affinegap.normalizedAffineGapDistance(s0, s1)\n",
    "    except: \n",
    "        d = -1\n",
    "    dist_norm.append([d, s0, s1])\n",
    "dist_norm = sorted(dist_norm, key=lambda x: x[0])\n",
    "print \"dist pairs: %d\"%len(dist_norm)\n",
    "threshold = 1\n",
    "res = [l for l in dist_norm if (l[0] <threshold and l[0]>0.5)]\n",
    "print \"dist smaller than threshold=%d: %d\"%(threshold, len(res))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "saved: dist_norm_20180309.csv\n"
     ]
    }
   ],
   "source": [
    "# save the file back to words to remove\n",
    "import myfunctions as f\n",
    "file_name = \"dist_norm_\" + f.today() + \".csv\"\n",
    "import csv\n",
    "with open(file_name, \"wb\") as output:\n",
    "    writer = csv.writer(output)\n",
    "    writer.writerows(res) \n",
    "print (\"saved: %s\" % file_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dist smaller than threshold=1: 102848\n",
      "CPU times: user 6h 22min 52s, sys: 2min 54s, total: 6h 25min 46s\n",
      "Wall time: 6h 21min 36s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# estimated 8 hours = 92077*92077/1000/1000*3.77/3600\n",
    "dist_norm = []\n",
    "import itertools\n",
    "for s0, s1 in itertools.combinations(food_names,2):\n",
    "    try:\n",
    "        d = affinegap.normalizedAffineGapDistance(s0, s1)\n",
    "        if d>0.5 and d<1:\n",
    "            dist_norm.append([d, s0, s1])\n",
    "    except: \n",
    "        pass\n",
    "dist_norm = sorted(dist_norm, key=lambda x: x[0])\n",
    "print \"dist smaller than threshold=%d: %d\"%(threshold, len(dist_norm))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "saved: dist_norm_20180309.csv\n"
     ]
    }
   ],
   "source": [
    "# save the file back to words to remove\n",
    "import myfunctions as f\n",
    "file_name = \"dist_norm_\" + f.today() + \".csv\"\n",
    "import csv\n",
    "with open(file_name, \"wb\") as output:\n",
    "    writer = csv.writer(output)\n",
    "    writer.writerows(dist_norm) \n",
    "print (\"saved: %s\" % file_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ">  Example pair \n",
    "\n",
    "> 0.559782624,\taloo mutter sukhewali,\taloo mutter sukhewali ali\n",
    "\n",
    "    consider multi-filed matching\n",
    "    -> description similarity > some desc_sim threshold\n",
    "    -> offered by the same restaurants \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'20180313'"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%reload_ext autoreload\n",
    "%autoreload 2\n",
    "import myfunctions as f\n",
    "f.today()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "size = 50\n",
    "sample_lst = [l[1:] for l in dist_norm[:size]]\n",
    "additional_words, lst = f.parallel_detection(sample_lst )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(u'set', 20),\n",
       " (u'fry', 3),\n",
       " (u'pan', 3),\n",
       " (u'france', 2),\n",
       " (u'cl', 1),\n",
       " (u'bento', 1),\n",
       " (u'nut', 1),\n",
       " (u'pc', 1),\n",
       " (u'veneto', 1),\n",
       " (u'soup', 1),\n",
       " (u'basket', 1),\n",
       " (u'new', 1),\n",
       " (u'rice', 1)]"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "additional_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{frozenset({u'sauc', u'sauce'}),\n",
       " frozenset({u'sandwic', u'sandwich'}),\n",
       " frozenset({u'aglio', u'set'}),\n",
       " frozenset({u'keema', u'keemah'}),\n",
       " frozenset({u'chill', u'chilli'}),\n",
       " frozenset({u'toast', u'toaste'}),\n",
       " frozenset({u'bit', u'bite'}),\n",
       " frozenset({u'oat', u'oats'}),\n",
       " frozenset({u'web', u'webs'}),\n",
       " frozenset({u'pc', u'pcs'}),\n",
       " frozenset({u'consomm', u'consomme'}),\n",
       " frozenset({u'pan fry', u'pcs steam and pcs sweet garlic'})}"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lst"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\"\"\" complete set with affine distance treshold = 0.6\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6996\n"
     ]
    }
   ],
   "source": [
    "size = len(dist_norm)\n",
    "threshold = 0.6\n",
    "sample_lst = [l[1:] for l in dist_norm[:size] if l[0] <threshold]\n",
    "print len(sample_lst)\n",
    "words_rmv, syn_lst = f.parallel_detection(sample_lst )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(u'rice', 822),\n",
       " (u'set', 776),\n",
       " (u'soup', 281),\n",
       " (u'with', 242),\n",
       " (u'egg', 185),\n",
       " (u'and', 184),\n",
       " (u'pasta', 157),\n",
       " (u'meal', 152),\n",
       " (u'fry', 147),\n",
       " (u'sauce', 146),\n",
       " (u'salad', 137),\n",
       " (u'noodle', 122),\n",
       " (u'pizza', 110),\n",
       " (u'bento', 97),\n",
       " (u'don', 86),\n",
       " (u'wing', 81),\n",
       " (u'dry', 79),\n",
       " (u'in', 73),\n",
       " (u'chop', 63),\n",
       " (u'wrap', 63)]"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "words_rmv[:20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "821"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(words_rmv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{frozenset({u'mentai', u'mentaiko'}),\n",
       " frozenset({u'frit', u'fritto'}),\n",
       " frozenset({u'cuttlefish', u'sambal'}),\n",
       " frozenset({u'hamburg', u'hamburger'}),\n",
       " frozenset({u'and chicken', u'bento'}),\n",
       " frozenset({u'chilli crab sauce', u'fry'}),\n",
       " frozenset({u'lemak', u'lemakk'}),\n",
       " frozenset({u'kulcha', u'kulchan'}),\n",
       " frozenset({u'salmon', u'salmone'}),\n",
       " frozenset({u'oat', u'oats'}),\n",
       " frozenset({u'aglio', u'spaghetti'}),\n",
       " frozenset({u'jalfrezi', u'jalfrezie'}),\n",
       " frozenset({u'egg', u'rice with sirloin steak'}),\n",
       " frozenset({u'aglio', u'pasta set'}),\n",
       " frozenset({u'bai', u'shrimp'}),\n",
       " frozenset({u'floss', u'flossant'}),\n",
       " frozenset({u'grill', u'grille'}),\n",
       " frozenset({u'burger', u'doo'}),\n",
       " frozenset({u'sauc', u'sauce'}),\n",
       " frozenset({u'chettina', u'chettinad'}),\n",
       " frozenset({u'egg', u'rice with chicken wing'}),\n",
       " frozenset({u'moo or gai', u'prawn'}),\n",
       " frozenset({u'aglio', u'thai sauce'}),\n",
       " frozenset({u'steam', u'steamfish'}),\n",
       " frozenset({u'gravy', u'seafood and egg'}),\n",
       " frozenset({u'pc', u'pcs'}),\n",
       " frozenset({u'vegetarian', u'vegetariano'}),\n",
       " frozenset({u'chick', u'chicken'}),\n",
       " frozenset({u'saag', u'saagwla'}),\n",
       " frozenset({u'pan fry', u'pcs steam and pcs sweet garlic'}),\n",
       " frozenset({u'katsu', u'katsugan'}),\n",
       " frozenset({u'chick', u'chicken nest'}),\n",
       " frozenset({u'aglio', u'mustard sauce'}),\n",
       " frozenset({u'veg', u'vege rice'}),\n",
       " frozenset({u'australia', u'cabernet sauvignon adelaide'}),\n",
       " frozenset({u'ric', u'rice egg'}),\n",
       " frozenset({u'platte', u'platter'}),\n",
       " frozenset({u'egg', u'eggy'}),\n",
       " frozenset({u'shishito', u'shishitou'}),\n",
       " frozenset({u'aglio veg', u'vege'}),\n",
       " frozenset({u'katsu', u'katsudon'}),\n",
       " frozenset({u'chic', u'chicken'}),\n",
       " frozenset({u'dumpl', u'dumploing'}),\n",
       " frozenset({u'pop', u'popper'}),\n",
       " frozenset({u'maki', u'makimono'}),\n",
       " frozenset({u'veg', u'vegetarian'}),\n",
       " frozenset({u'frit', u'fritter'}),\n",
       " frozenset({u'teppan', u'teppanyaki'}),\n",
       " frozenset({u'zurich', u'zurichiose'}),\n",
       " frozenset({u'noodle', u'shabu'}),\n",
       " frozenset({u'sal', u'salad'}),\n",
       " frozenset({u'toast', u'toastie without egg'}),\n",
       " frozenset({u'bell', u'belly'}),\n",
       " frozenset({u'bell', u'belly large'}),\n",
       " frozenset({u'aglio', u'funghi'}),\n",
       " frozenset({u'fry egg', u'sour chicken with rice'}),\n",
       " frozenset({u'broth gaeng som pla', u'fillet'}),\n",
       " frozenset({u'heisenberg', u'heisenberger'}),\n",
       " frozenset({u'pla', u'plaa'}),\n",
       " frozenset({u'bell', u'belly small'}),\n",
       " frozenset({u'sashimi', u'sashimii'}),\n",
       " frozenset({u'sou', u'soup'}),\n",
       " frozenset({u'pork', u'porky'}),\n",
       " frozenset({u'rice', u'ricebox'}),\n",
       " frozenset({u'aglio', u'seafood'}),\n",
       " frozenset({u'mama', u'mamak'}),\n",
       " frozenset({u'burg', u'burger'}),\n",
       " frozenset({u'mediterranea', u'mediterranean'}),\n",
       " frozenset({u'mori', u'moriawase'}),\n",
       " frozenset({u'chap', u'chapati'}),\n",
       " frozenset({u'pepper', u'pepperoni'}),\n",
       " frozenset({u'aglio veg', u'veggie'}),\n",
       " frozenset({u'sua', u'suan'}),\n",
       " frozenset({u'chicken with chilli sauce', u'rice'}),\n",
       " frozenset({u'cannibal', u'cannibale'}),\n",
       " frozenset({u'duck', u'ducky'}),\n",
       " frozenset({u'tepon', u'tepong'}),\n",
       " frozenset({u'cheese', u'cheeseburger'}),\n",
       " frozenset({u'don', u'doner'}),\n",
       " frozenset({u'fum', u'fume'}),\n",
       " frozenset({u'egg', u'sour fish with rice'}),\n",
       " frozenset({u'nacho', u'nachos'}),\n",
       " frozenset({u'cheese', u'cheeseball'}),\n",
       " frozenset({u'basil', u'century egg'}),\n",
       " frozenset({u'ben', u'benedict'}),\n",
       " frozenset({u'bread', u'breadstck'}),\n",
       " frozenset({u'cap', u'capellini'}),\n",
       " frozenset({u'lamb', u'lambloin'}),\n",
       " frozenset({u'pizza', u'pizzazz'}),\n",
       " frozenset({u'sala', u'salad'}),\n",
       " frozenset({u'cheese', u'cheesekcake'}),\n",
       " frozenset({u'bom', u'bomb'}),\n",
       " frozenset({u'maki', u'makikyu'}),\n",
       " frozenset({u'marina', u'marinana'}),\n",
       " frozenset({u'carb', u'carbonara'}),\n",
       " frozenset({u'egg', u'sour chicken with rice'}),\n",
       " frozenset({u'vege', u'vegetarian'}),\n",
       " frozenset({u'na', u'nah'}),\n",
       " frozenset({u'chimichanga', u'chimichangas'}),\n",
       " frozenset({u'duck', u'duckie'}),\n",
       " frozenset({u'pc', u'pcs fry'}),\n",
       " frozenset({u'makhanwal', u'makhanwala'}),\n",
       " frozenset({u'dry chilli', u'egg'}),\n",
       " frozenset({u'keema', u'keemah'}),\n",
       " frozenset({u'black pepper sauce', u'rice'}),\n",
       " frozenset({u'tender', u'tenderloin'}),\n",
       " frozenset({u'veg', u'vegatable'}),\n",
       " frozenset({u'chic', u'chick'}),\n",
       " frozenset({u'consomm', u'consomme'}),\n",
       " frozenset({u'bai', u'garlic'}),\n",
       " frozenset({u'ric', u'rice'}),\n",
       " frozenset({u'mit', u'mitr'}),\n",
       " frozenset({u'melon', u'melone'}),\n",
       " frozenset({u'broccoli', u'broccolini'}),\n",
       " frozenset({u'meat', u'meatball'}),\n",
       " frozenset({u'napoli', u'napolizz'}),\n",
       " frozenset({u'ayam', u'kong'}),\n",
       " frozenset({u'don', u'donburi set'}),\n",
       " frozenset({u'fizz', u'fizzy'}),\n",
       " frozenset({u'cream', u'creamy pasta'}),\n",
       " frozenset({u'namba', u'namban'}),\n",
       " frozenset({u'by half', u'vegetarian'}),\n",
       " frozenset({u'ric', u'rice set'}),\n",
       " frozenset({u'rice', u'sambal chicken'}),\n",
       " frozenset({u'fizz', u'fizzy soda'}),\n",
       " frozenset({u'po', u'poh'}),\n",
       " frozenset({u'toast', u'toaste'}),\n",
       " frozenset({u'aglio', u'pasta'}),\n",
       " frozenset({u'mist', u'mista'}),\n",
       " frozenset({u'kare', u'set'}),\n",
       " frozenset({u'prata', u'prataa'}),\n",
       " frozenset({u'superi', u'superior stock'}),\n",
       " frozenset({u'royal', u'royale'}),\n",
       " frozenset({u'veg', u'vege and dal'}),\n",
       " frozenset({u'aglio vege', u'vegetarian'}),\n",
       " frozenset({u'churro', u'churros'}),\n",
       " frozenset({u'bell', u'belly salad'}),\n",
       " frozenset({u'cavalieri montepulciano abruzzo', u'chieti'}),\n",
       " frozenset({u'chicken wing with fry', u'rice'}),\n",
       " frozenset({u'jjajang bap bap', u'rice'}),\n",
       " frozenset({u'don', u'dondon'}),\n",
       " frozenset({u'veg', u'vegetable'}),\n",
       " frozenset({u'omelet', u'omelete'}),\n",
       " frozenset({u'daging', u'kong'}),\n",
       " frozenset({u'chill', u'chilli'}),\n",
       " frozenset({u'toast', u'toastie'}),\n",
       " frozenset({u'acha', u'achar'}),\n",
       " frozenset({u'egg', u'eggg'}),\n",
       " frozenset({u'panee', u'paneer'}),\n",
       " frozenset({u'cocktail', u'cocktailv'}),\n",
       " frozenset({u'ball', u'steak slice'}),\n",
       " frozenset({u'bologne', u'bolognese'}),\n",
       " frozenset({u'camaron', u'camarone'}),\n",
       " frozenset({u'australia', u'cabernet sauvignon adelaide hill'}),\n",
       " frozenset({u'don', u'donburi'}),\n",
       " frozenset({u'croissant', u'croissantwich'}),\n",
       " frozenset({u'kha', u'khaas'}),\n",
       " frozenset({u'cous', u'salad'}),\n",
       " frozenset({u'ice', u'iced tea'}),\n",
       " frozenset({u'kong', u'seafood'}),\n",
       " frozenset({u'pizza', u'pizzaiola'}),\n",
       " frozenset({u'meat', u'meatbox'}),\n",
       " frozenset({u'sua', u'suah with egg'}),\n",
       " frozenset({u'classic', u'classico'}),\n",
       " frozenset({u'cheese', u'cheeseq'}),\n",
       " frozenset({u'preserve vegetable', u'rice set'}),\n",
       " frozenset({u'pok', u'poke'}),\n",
       " frozenset({u'chicken char si ew', u'pork'}),\n",
       " frozenset({u'clam', u'clams'}),\n",
       " frozenset({u'bil', u'bili'}),\n",
       " frozenset({u'aglio', u'salmon'}),\n",
       " frozenset({u'sardin', u'sardine'}),\n",
       " frozenset({u'sicilian', u'siciliana'}),\n",
       " frozenset({u'kon', u'kone'}),\n",
       " frozenset({u'yam', u'yum'}),\n",
       " frozenset({u'fill', u'fillet'}),\n",
       " frozenset({u'salad', u'shabu'}),\n",
       " frozenset({u'hawaii', u'hawaiiana'}),\n",
       " frozenset({u'veg', u'vegetable rice'}),\n",
       " frozenset({u'liver', u'spring onion pork'}),\n",
       " frozenset({u'egg', u'rice with'}),\n",
       " frozenset({u'moussaka', u'moussakaa'}),\n",
       " frozenset({u'bai', u'veg'}),\n",
       " frozenset({u'chap', u'chapli'}),\n",
       " frozenset({u'chicken', u'with'}),\n",
       " frozenset({u'sauce', u'seafood'}),\n",
       " frozenset({u'fillet', u'nasi lemak'}),\n",
       " frozenset({u'meat', u'meatloaf'}),\n",
       " frozenset({u'love', u'lover'}),\n",
       " frozenset({u'sua', u'suah'}),\n",
       " frozenset({u'aglio', u'set'}),\n",
       " frozenset({u'marina', u'marinara'}),\n",
       " frozenset({u'zurich', u'zurichoise'}),\n",
       " frozenset({u'web', u'webs'}),\n",
       " frozenset({u'pesce', u'pesco'}),\n",
       " frozenset({u'spaghetti', u'spaghettini'}),\n",
       " frozenset({u'wing', u'winglet'}),\n",
       " frozenset({u'drumlet', u'drumlett'}),\n",
       " frozenset({u'pineapple', u'sour pork with lychee'}),\n",
       " frozenset({u'rice', u'ricebowl'}),\n",
       " frozenset({u'cream', u'creamy'}),\n",
       " frozenset({u'pork', u'porku'}),\n",
       " frozenset({u'aglio', u'sambal sauce'}),\n",
       " frozenset({u'hawaii', u'hawaiian'}),\n",
       " frozenset({u'veg', u'veggie'}),\n",
       " frozenset({u'omelet', u'omelette'}),\n",
       " frozenset({u'hawaiian', u'hawaiiana'}),\n",
       " frozenset({u'fish', u'fishhead'}),\n",
       " frozenset({u'stack', u'stacker'}),\n",
       " frozenset({u'rice', u'roasted pork'}),\n",
       " frozenset({u'bai veg', u'vege'}),\n",
       " frozenset({u'crudit', u'crudite'}),\n",
       " frozenset({u'dhal', u'dhall'}),\n",
       " frozenset({u'angar', u'angara'}),\n",
       " frozenset({u'prawn', u'sauce'}),\n",
       " frozenset({u'aglio', u'prawn'}),\n",
       " frozenset({u'gril', u'grill'}),\n",
       " frozenset({u'vindalo', u'vindaloo'}),\n",
       " frozenset({u'pig', u'piglet'}),\n",
       " frozenset({u'sandwic', u'sandwich'}),\n",
       " frozenset({u'california', u'californian'}),\n",
       " frozenset({u'bit', u'bite'}),\n",
       " frozenset({u'vege', u'vegetable'}),\n",
       " frozenset({u'frank', u'frankie'}),\n",
       " frozenset({u'veg', u'vege'}),\n",
       " frozenset({u'dry chilli rice', u'egg'}),\n",
       " frozenset({u'hara', u'harasu'}),\n",
       " frozenset({u'roll', u'rolll'})}"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "syn_lst"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "228"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(syn_lst)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
