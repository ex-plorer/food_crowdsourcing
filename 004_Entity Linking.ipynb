{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Retrive ES data for Bruppleinitial and Burpple\n",
    "    save the object with pickle"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "    >'burpple__review__unique__***today***.p',   \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Conenct with ES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'20180313'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "import myfunctions as f\n",
    "f.today()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "system_info: 2.7.14 |Anaconda custom (64-bit)| (default, Oct 27 2017, 18:21:12) \n",
      "[GCC 7.2.0]\n",
      "path_info: /home/yueliu/Desktop/workspace_yue/Documentation_201712\n",
      "es_info: http://10.0.109.54:9200\n"
     ]
    }
   ],
   "source": [
    "# set up ElasticSearch object and the URL to access it\n",
    "def setup_es(isServer):\n",
    "    # python version\n",
    "    import sys\n",
    "    print \"system_info: %s\"%sys.version\n",
    "    # current working directory\n",
    "    import os\n",
    "    print \"path_info: %s\"%os.getcwd()    \n",
    "    ## Local on PC/laptop or on VM (10.0.106.122:2)   \n",
    "    from elasticsearch import Elasticsearch\n",
    "    port = \"9200\"\n",
    "    host = \"localhost\"\n",
    "    if isServer:\n",
    "        host = \"10.0.109.54\"    \n",
    "    url = \"http://\" + host + \":\" + port    \n",
    "    print \"es_info: %s\"%url    \n",
    "    es = Elasticsearch([{'host': host, 'port': port}])\n",
    "    return es, url\n",
    "\n",
    "es, url = setup_es(True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "  \"name\" : \"star7\",\n",
      "  \"cluster_name\" : \"star\",\n",
      "  \"cluster_uuid\" : \"VDcV69ThThyb00sd6PgeMA\",\n",
      "  \"version\" : {\n",
      "    \"number\" : \"2.4.5\",\n",
      "    \"build_hash\" : \"c849dd13904f53e63e88efc33b2ceeda0b6a1276\",\n",
      "    \"build_timestamp\" : \"2017-04-24T16:18:17Z\",\n",
      "    \"build_snapshot\" : false,\n",
      "    \"lucene_version\" : \"5.5.4\"\n",
      "  },\n",
      "  \"tagline\" : \"You Know, for Search\"\n",
      "}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# make sure ES is up and running\n",
    "import requests\n",
    "def initialise_es(i):\n",
    "    res = requests.get(url)\n",
    "    if i:\n",
    "        print(res.content)\n",
    "initialise_es(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# define dict for b and bi\n",
    "burpple = {\"_index\":\"burpple\"}\n",
    "burppleinitial = {\"_index\":\"burppleinitial\"}\n",
    "burpples = [burpple, burppleinitial]\n",
    "for website in burpples:\n",
    "    website.update({\"vendor\":\"restaurant\",\n",
    "                    \"review\":\"review\",  \n",
    "                    \"user\":\"user\",                                   \n",
    "                    \"_id\":\"_id\",\n",
    "                    \"vendor_id\":'_source.id',\n",
    "                    \"vendor_url\":'_source.url',\n",
    "                    \"vendor_name\":\"_source.name\", \n",
    "                    \"address\":\"_source.address\", \n",
    "                    \"cuisine_tags\":\"_source.tags\", \n",
    "                    \"phone\":\"_source.phone\",                \n",
    "                    \"cycleStart\":'_source.crawlTimeStamp'})    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "burpple.update({\"reviewFeedTime\":'_source.feedDatetime',})\n",
    "burppleinitial.update({\"reviewFeedTime\":'_source.datetime',})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Actual data retrival"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def retrive_data (website, doc_type):\n",
    "    # activate ES\n",
    "    initialise_es(0)\n",
    "    # ES search pattern\n",
    "    _body = {\"query\": {\"match_all\": {}}}\n",
    "    _index = website['_index']\n",
    "    _doc_type = website[doc_type]\n",
    "\n",
    "    # With the help of a generator, get all records\n",
    "    from elasticsearch import helpers\n",
    "    scanResp = helpers.scan(es, _body, scroll= \"2m\", \n",
    "                            index= _index, \n",
    "                            doc_type= _doc_type, \n",
    "                            timeout=\"2m\")\n",
    "    recs = []\n",
    "    for rec in scanResp:\n",
    "        recs.append(rec)\n",
    "    print len(recs)\n",
    "\n",
    "    # Convert unicode to string (ascii, ignore unicode such as '\\xae')\n",
    "    def convert_unicode(data):\n",
    "        if isinstance(data, basestring):\n",
    "            return (data.encode(\"ascii\",\"ignore\"))\n",
    "        elif isinstance(data, collections.Mapping):\n",
    "            return dict(map(convert_unicode, data.iteritems()))\n",
    "        elif isinstance(data, collections.Iterable):\n",
    "            return type(data)(map(convert_unicode, data))\n",
    "        else:\n",
    "            return data\n",
    "\n",
    "    # json file to dataframe \n",
    "    import collections\n",
    "    import pandas as pd\n",
    "    pd.options.mode.chained_assignment = None # default is warn\n",
    "    from pandas.io.json import json_normalize\n",
    "    lst_rec = []\n",
    "    for line in recs:\n",
    "        line = convert_unicode(line)\n",
    "        lst_rec.append(json_normalize(line))    \n",
    "    df = pd.concat(lst_rec) \n",
    "    # Print shape and all attributes\n",
    "    print (\"ES location: %s, %s\"%(_index,website[doc_type]))\n",
    "    print(\"Dimention: %d , %d\"%df.shape)\n",
    "    print(\"Column names::%s\"%\", \".join(df.columns.tolist()))\n",
    "    print (\"\\n\")\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "  \"name\" : \"star7\",\n",
      "  \"cluster_name\" : \"star\",\n",
      "  \"cluster_uuid\" : \"VDcV69ThThyb00sd6PgeMA\",\n",
      "  \"version\" : {\n",
      "    \"number\" : \"2.4.5\",\n",
      "    \"build_hash\" : \"c849dd13904f53e63e88efc33b2ceeda0b6a1276\",\n",
      "    \"build_timestamp\" : \"2017-04-24T16:18:17Z\",\n",
      "    \"build_snapshot\" : false,\n",
      "    \"lucene_version\" : \"5.5.4\"\n",
      "  },\n",
      "  \"tagline\" : \"You Know, for Search\"\n",
      "}\n",
      "\n",
      "\n",
      "25709\n",
      "ES location: burpple, review\n",
      "Dimention: 25709 , 43\n",
      "Column names::_id, _index, _score, _source.body, _source.crawlTimeStamp, _source.feedDatetime, _source.foodImgUrl, _source.id, _source.name, _source.postDatetime, _source.restaurant, _source.restaurant.address, _source.restaurant.areaUrls, _source.restaurant.avgPrice, _source.restaurant.crawlTimeStamp, _source.restaurant.id, _source.restaurant.name, _source.restaurant.openingHours, _source.restaurant.phone, _source.restaurant.tags, _source.restaurant.url, _source.restaurant.website, _source.restaurantUrl, _source.title, _source.url, _source.user, _source.user.awards, _source.user.badges, _source.user.bio, _source.user.country, _source.user.crawlTimeStamp, _source.user.name, _source.user.numOfFollowers, _source.user.numOfFollowing, _source.user.numOfReviews, _source.user.numOfWishlists, _source.user.url, _source.user.userImgUrl, _source.user.username, _source.user.website, _source.userImgUrl, _source.username, _type\n",
      "\n",
      "\n",
      "CPU times: user 2min 30s, sys: 3.69 s, total: 2min 33s\n",
      "Wall time: 2min 33s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "initialise_es(1)\n",
    "print \"\"\n",
    "\n",
    "website = burpple\n",
    "website.update({\"all_rec_review\" : retrive_data (website, \"review\")})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "297480\n",
      "ES location: burppleinitial, review\n",
      "Dimention: 297480 , 44\n",
      "Column names::_id, _index, _score, _source.areaName, _source.body, _source.crawlTimeStamp, _source.datetime, _source.foodImgUrl, _source.id, _source.name, _source.offset, _source.restaurant, _source.restaurant.address, _source.restaurant.areaUrls, _source.restaurant.avgPrice, _source.restaurant.crawlTimeStamp, _source.restaurant.id, _source.restaurant.name, _source.restaurant.openingHours, _source.restaurant.phone, _source.restaurant.tags, _source.restaurant.url, _source.restaurant.website, _source.restaurantUrl, _source.title, _source.url, _source.user, _source.user.awards, _source.user.badges, _source.user.bio, _source.user.country, _source.user.crawlTimeStamp, _source.user.name, _source.user.numOfFollowers, _source.user.numOfFollowing, _source.user.numOfReviews, _source.user.numOfWishlists, _source.user.url, _source.user.userImgUrl, _source.user.username, _source.user.website, _source.userImgUrl, _source.username, _type\n",
      "\n",
      "\n",
      "CPU times: user 29min 58s, sys: 37.1 s, total: 30min 35s\n",
      "Wall time: 30min 49s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "website = burppleinitial\n",
    "website.update({\"all_rec_review\" : retrive_data (website, \"review\")})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Duplicate records removal  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def remove_bu_dup_records(burpples, non_sg_vendors):\n",
    "    # not included: '_source.url', # https://www.burpple.com/f/ + \"_id\"\n",
    "    cols = ['_id', # review identifier, something like \"liKrL-pE\"\n",
    "            '_type',\n",
    "            '_index', # burpple / burpple initial\n",
    "            '_source.title', # title of review, with some special characters\n",
    "            '_source.body', # text \n",
    "            '_source.crawlTimeStamp', \n",
    "            '_source.foodImgUrl',             \n",
    "            '_source.username', # user identifier\n",
    "            '_source.restaurant.id',\n",
    "            '_source.restaurant.name'] #vendor identifier\n",
    "    # merge feed time\n",
    "    import pandas as pd\n",
    "    pd.options.mode.chained_assignment = None # default is warn\n",
    "    df = pd.concat([site[\"all_rec_review\"]\n",
    "                    [cols+ [site[\"reviewFeedTime\"]]] for site in burpples])\n",
    "    df[\"feedTime\"] = df[[site[\"reviewFeedTime\"] for site in burpples]].fillna('').sum(axis=1)\n",
    "    df = df[cols +[\"feedTime\"]]\n",
    "    # sort, only leaving the latest crawled first\n",
    "    df = df.sort_values(by=['_source.crawlTimeStamp',\"_id\"], ascending=[False,True])\n",
    "    df = df.groupby(\"_id\").first()\n",
    "    df.reset_index(inplace=True)\n",
    "    # remove reviews of non-sg vendors\n",
    "    df = df[~df[\"_source.restaurant.id\"].isin(non_sg_vendors)]\n",
    "    \n",
    "    print (\"Got %d unique records of review\" % len(df))\n",
    "    print (\"Got %d unique records of images\" % \n",
    "           df[df['_source.foodImgUrl']!=\"\"]['_source.foodImgUrl'].nunique())\n",
    "    print (\"Got %d unique users\" % df['_source.username'].nunique())\n",
    "    print (\"Got %d unique vendors\" % df['_source.restaurant.id'].nunique())\n",
    "    print (\"Review time from %s to %s\" % (df['feedTime'].min(),df['feedTime'].max()))\n",
    "    return df\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Got 323104 unique records of review\n",
      "Got 323051 unique records of images\n",
      "Got 11180 unique users\n",
      "Got 14547 unique vendors\n",
      "Review time from 2011-11-08 00:00:00.000000 to 2017-07-20 23:04:45.837391\n",
      "CPU times: user 8.06 s, sys: 276 ms, total: 8.33 s\n",
      "Wall time: 8.33 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "non_sg_vendors = ['114803', '119954', '136868', '139058', '149618', '155202', '156512', '16431',\n",
    "                  '165933', '166041', '174029', '28318', '43464', '51131', '59732', '63212']\n",
    "df = remove_bu_dup_records(burpples, non_sg_vendors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>_id</th>\n",
       "      <th>_type</th>\n",
       "      <th>_index</th>\n",
       "      <th>_source.title</th>\n",
       "      <th>_source.body</th>\n",
       "      <th>_source.crawlTimeStamp</th>\n",
       "      <th>_source.foodImgUrl</th>\n",
       "      <th>_source.username</th>\n",
       "      <th>_source.restaurant.id</th>\n",
       "      <th>_source.restaurant.name</th>\n",
       "      <th>feedTime</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>--0EG2cp</td>\n",
       "      <td>review</td>\n",
       "      <td>burppleinitial</td>\n",
       "      <td>Sicilian Lemon Creme andCaramelized Red Mixed ...</td>\n",
       "      <td></td>\n",
       "      <td>2017-04-03 11:00:52.282519</td>\n",
       "      <td>https://s3.burpple.com/foods/376d87a944deb0499...</td>\n",
       "      <td>@ieatkows</td>\n",
       "      <td>34166</td>\n",
       "      <td>OSO Ristorante</td>\n",
       "      <td>2014-12-22 00:00:00.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>--0ck5YP</td>\n",
       "      <td>review</td>\n",
       "      <td>burppleinitial</td>\n",
       "      <td>Just look at their soy sauce chicken.</td>\n",
       "      <td>The tender and juicy thigh meat with their fra...</td>\n",
       "      <td>2017-04-03 11:00:52.282519</td>\n",
       "      <td>https://s3.burpple.com/foods/2fbab5e890cf97f31...</td>\n",
       "      <td>@jiaknonstop</td>\n",
       "      <td>164762</td>\n",
       "      <td>Fatty Ox Hong Kong Kitchen (Chinatown Complex ...</td>\n",
       "      <td>2014-12-15 00:00:00.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>--0gMGRO</td>\n",
       "      <td>review</td>\n",
       "      <td>burppleinitial</td>\n",
       "      <td>Holy, smokin' Burnt Corn Tacos - it's their WE...</td>\n",
       "      <td>(Read: time for MORE alcohol.)  #AntiDoteBar #...</td>\n",
       "      <td>2017-04-03 11:00:52.282519</td>\n",
       "      <td>https://s3.burpple.com/foods/16ff778f20e5f8614...</td>\n",
       "      <td>@Jazpster</td>\n",
       "      <td>539</td>\n",
       "      <td>Asian Market Caf (Fairmont Singapore)</td>\n",
       "      <td>2016-11-18 00:00:00.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        _id   _type          _index  \\\n",
       "0  --0EG2cp  review  burppleinitial   \n",
       "1  --0ck5YP  review  burppleinitial   \n",
       "2  --0gMGRO  review  burppleinitial   \n",
       "\n",
       "                                       _source.title  \\\n",
       "0  Sicilian Lemon Creme andCaramelized Red Mixed ...   \n",
       "1              Just look at their soy sauce chicken.   \n",
       "2  Holy, smokin' Burnt Corn Tacos - it's their WE...   \n",
       "\n",
       "                                        _source.body  \\\n",
       "0                                                      \n",
       "1  The tender and juicy thigh meat with their fra...   \n",
       "2  (Read: time for MORE alcohol.)  #AntiDoteBar #...   \n",
       "\n",
       "       _source.crawlTimeStamp  \\\n",
       "0  2017-04-03 11:00:52.282519   \n",
       "1  2017-04-03 11:00:52.282519   \n",
       "2  2017-04-03 11:00:52.282519   \n",
       "\n",
       "                                  _source.foodImgUrl _source.username  \\\n",
       "0  https://s3.burpple.com/foods/376d87a944deb0499...        @ieatkows   \n",
       "1  https://s3.burpple.com/foods/2fbab5e890cf97f31...     @jiaknonstop   \n",
       "2  https://s3.burpple.com/foods/16ff778f20e5f8614...        @Jazpster   \n",
       "\n",
       "  _source.restaurant.id                            _source.restaurant.name  \\\n",
       "0                 34166                                     OSO Ristorante   \n",
       "1                164762  Fatty Ox Hong Kong Kitchen (Chinatown Complex ...   \n",
       "2                   539              Asian Market Caf (Fairmont Singapore)   \n",
       "\n",
       "                     feedTime  \n",
       "0  2014-12-22 00:00:00.000000  \n",
       "1  2014-12-15 00:00:00.000000  \n",
       "2  2016-11-18 00:00:00.000000  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Save Files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "burpple__review__unique__20180313.p\n",
      "CPU times: user 17.5 s, sys: 452 ms, total: 18 s\n",
      "Wall time: 18 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "file_name = \"burpple__review__unique__\"+f.today()+\".p\"\n",
    "f.save_files(df, file_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Further cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'20180317'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "import myfunctions as f\n",
    "f.today()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "system_info: 2.7.14 |Anaconda custom (64-bit)| (default, Oct 27 2017, 18:21:12) \n",
      "[GCC 7.2.0]\n",
      "path_info: /home/yueliu/Desktop/workspace_yue/Documentation_201712\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "print \"system_info: %s\"%sys.version\n",
    "# current working directory\n",
    "import os\n",
    "print \"path_info: %s\"%os.getcwd() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "retrived: burpple__review__unique__20180313.p\n"
     ]
    }
   ],
   "source": [
    "file_name = \"burpple__review__unique__20180313.p\"    \n",
    "df = f.retrive_file(file_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Obtain review objects with clean text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "pd.options.mode.chained_assignment = None # default is warn\n",
    "# new col: loc\n",
    "df[\"loc\"] = df[\"_index\"] + \"/\" + df[\"_type\"] + \"/\" + df[\"_id\"] \n",
    "cols = ['loc','_source.title','_source.body','_source.restaurant.name']\n",
    "df = df[cols]\n",
    "rename_cols = [col.replace(\"_source.\", \"\") for col in cols]\n",
    "df.columns = rename_cols\n",
    "# new col: full_review\n",
    "df[\"full_review\"] = df['title'] + \" \" + df['body']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\"\"\" \n",
    "twitter style text-cleaning, for url, mention, hashtag, \n",
    "also: dollar, score\n",
    "not: apostrophe conversion, stop words, emoticons, slang, word standardization\n",
    "\"\"\"\n",
    "def clean_review(s):\n",
    "    import re   \n",
    "    # 1. etract urls (may contain $, #, @), remove url part from s\n",
    "    p = r'http[s]?://(?:[a-z]|[0-9]|[$-_@#.&amp;+]|[!*\\(\\),]|(?:%[0-9a-f][0-9a-f]))+'\n",
    "    urls = tuple(re.findall(p, s))\n",
    "    for rep in urls:\n",
    "        s = s.replace(rep,\"\")\n",
    "    # 2. normal cleaning: replace w/ and &\n",
    "    s = \" \" + s +\" \"\n",
    "    s = s.replace(\"w/\", \" with \")\n",
    "    s = s.replace(\"&\", \" and \") \n",
    "    # 3. textract hashtags \n",
    "    hashtags = tuple(re.findall(r\"(?:\\#+[\\w_]+[\\w\\'_\\-]*[\\w_]+)\", s))\n",
    "    # 4. extract mentions\n",
    "    mentions = tuple(re.findall(r'(?:@[\\w_]+)', s))   \n",
    "    # 5. extract dolalr amounts\n",
    "    dollars = tuple([x[0] for x in re.findall(r'(\\$\\d+([,\\.]\\d+)?(\\+\\+)?(\\+)?k?)', s)])\n",
    "    # 6. extract scores\n",
    "    scores = tuple([x[0] for x in re.findall(r'(\\d+([\\.]\\d+)(\\/)\\d+([\\.]\\d+)?)', s)])\n",
    "    # 7. remove above parts from review, strip and remove multiple space\n",
    "    words = sorted(list(dollars + scores + hashtags + mentions), key=len, reverse=True)\n",
    "    for rep in words:\n",
    "        s = s.replace(rep,\"\")\n",
    "    s = re.sub(' +',' ', s.strip()) \n",
    "    lst = [s, hashtags, mentions, dollars, scores, urls]\n",
    "    return (tuple(lst))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 15.3 s, sys: 652 ms, total: 16 s\n",
      "Wall time: 15.8 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "df[\"review_text\"], df[\"hashtags\"], df[\"mentions\"], df[\"dollars\"], df[\"scores\"], df[\"urls\"] = \\\n",
    "zip(*df[\"full_review\"].apply(clean_review))\n",
    "cols = df.columns.tolist()\n",
    "cols.remove(\"full_review\")\n",
    "df = df[cols]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 22.8 s, sys: 56 ms, total: 22.9 s\n",
      "Wall time: 22.9 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# On review text, perform clean_name_v2()\n",
    "df[\"clean_review\"] = df[\"review_text\"].apply(f.clean_name_v2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(323104, 11)\n",
      "['loc', 'title', 'body', 'restaurant.name', 'review_text', 'hashtags', 'mentions', 'dollars', 'scores', 'urls', 'clean_review']\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>loc</th>\n",
       "      <th>title</th>\n",
       "      <th>body</th>\n",
       "      <th>restaurant.name</th>\n",
       "      <th>review_text</th>\n",
       "      <th>hashtags</th>\n",
       "      <th>mentions</th>\n",
       "      <th>dollars</th>\n",
       "      <th>scores</th>\n",
       "      <th>urls</th>\n",
       "      <th>clean_review</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>242662</th>\n",
       "      <td>burppleinitial/review/jnF_zvaY</td>\n",
       "      <td>Aged Cheddar, Fig &amp; #Cognac Jam and Candied Wa...</td>\n",
       "      <td>Aged Cheddar, Fig &amp; #Cognac Jam and Candied Wa...</td>\n",
       "      <td>The Humble Loaf</td>\n",
       "      <td>Aged Cheddar, Fig and Jam and Candied Walnuts ...</td>\n",
       "      <td>(#Cognac, #lunch, #weekend, #Cognac, #lunch, #...</td>\n",
       "      <td>()</td>\n",
       "      <td>()</td>\n",
       "      <td>()</td>\n",
       "      <td>()</td>\n",
       "      <td>aged cheddar fig and jam and candied walnuts o...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>74846</th>\n",
       "      <td>burppleinitial/review/CzDetUln</td>\n",
       "      <td>Orange Brioche</td>\n",
       "      <td></td>\n",
       "      <td>Artisan Boulangerie Co. (Great World City)</td>\n",
       "      <td>Orange Brioche</td>\n",
       "      <td>()</td>\n",
       "      <td>()</td>\n",
       "      <td>()</td>\n",
       "      <td>()</td>\n",
       "      <td>()</td>\n",
       "      <td>orange brioche</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                   loc  \\\n",
       "242662  burppleinitial/review/jnF_zvaY   \n",
       "74846   burppleinitial/review/CzDetUln   \n",
       "\n",
       "                                                    title  \\\n",
       "242662  Aged Cheddar, Fig & #Cognac Jam and Candied Wa...   \n",
       "74846                                      Orange Brioche   \n",
       "\n",
       "                                                     body  \\\n",
       "242662  Aged Cheddar, Fig & #Cognac Jam and Candied Wa...   \n",
       "74846                                                       \n",
       "\n",
       "                                   restaurant.name  \\\n",
       "242662                             The Humble Loaf   \n",
       "74846   Artisan Boulangerie Co. (Great World City)   \n",
       "\n",
       "                                              review_text  \\\n",
       "242662  Aged Cheddar, Fig and Jam and Candied Walnuts ...   \n",
       "74846                                      Orange Brioche   \n",
       "\n",
       "                                                 hashtags mentions dollars  \\\n",
       "242662  (#Cognac, #lunch, #weekend, #Cognac, #lunch, #...       ()      ()   \n",
       "74846                                                  ()       ()      ()   \n",
       "\n",
       "       scores urls                                       clean_review  \n",
       "242662     ()   ()  aged cheddar fig and jam and candied walnuts o...  \n",
       "74846      ()   ()                                     orange brioche  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print df.shape\n",
    "print df.columns.tolist()\n",
    "df.sample(2,random_state=2008)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "saved: burpple__review__clean__20180317.p\n",
      "CPU times: user 17.3 s, sys: 632 ms, total: 17.9 s\n",
      "Wall time: 17.9 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "file_name = \"burpple__review__clean__\"+f.today()+\".p\"\n",
    "f.save_file(df, file_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of unique reviews: 277772\n"
     ]
    }
   ],
   "source": [
    "all_reviews = sorted([s for s in set(df[\"clean_review\"].tolist()) if len(s)>0])\n",
    "print \"number of unique reviews: %d\"%len(all_reviews)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** retrive food items**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "retrived: food_entities__20180317.p\n"
     ]
    }
   ],
   "source": [
    "file_name = \"food_entities__20180317.p\"\n",
    "food_entities = f.retrive_file(file_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of food searched for: 139083\n"
     ]
    }
   ],
   "source": [
    "food_entities = food_entities.reset_index()\n",
    "# remove food of \" and \"-PRON-\"\n",
    "food_entities = food_entities[~food_entities[\"assigned_name\"].isin([\"\", \"-PRON-\"])]\n",
    "# food name variant : food_item_index\n",
    "index_ref = dict()\n",
    "def add_ref(line):\n",
    "    v = line[\"index\"]\n",
    "    index_ref.update({k:v for k in line[\"name_variants\"]})\n",
    "food_entities.apply(add_ref, axis =1)\n",
    "food_items = index_ref.keys()\n",
    "print \"number of food searched for: %d\"%len(food_items)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "file_name = \"words_to_remove_20180308.csv\"\n",
    "rmv = pd.read_csv(file_name, header=None)[0].tolist()\n",
    "rmv = rmv+['can', 'sweet', 'love', 'up', 'no', 'me', 'back', 'fluffy', 'hot', 'spicy', 'crisp', 'salty', 'house', 'red', 'fat', 'roasted', 'white', 'refreshing', 'black', 'cold', 'deep fried', 'pieces', 'toasted', 'skin', 'cheesy', 'hungry', 'pop', 'miss', 'option', 'fried', 'tomato', 'vanilla', 'plus', 'potato', 'thai', 'spice', 'infused', 'sauces', 'to share', 'lover', 'surprise', 'balanced', 'choice', 'french', 'green', 'steamed', 'italian', 'wake up', 'silver', 'savoury flavours', 'western', 'set for', 'pan fried', 'the original', 'decadence', 'the great', 'uplifting', 'all in', 'meaty', 'spice level', 'per slice', 'discovery', 'smokey', 'all time favourites', 'sticky', 'the double', 'pint', 'mad', 'singapore style', 'alcoholic', 'serves', 'nutty', 'salted', 'lunch set', 'boost', 'anything', 'dips', 'vietnamese', 'set lunch', 'lager', 'for pax', 'below', 'bundle']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def search_food(review):\n",
    "    return [s for s in f.search_food(review, values=food_items) if s not in rmv]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 52 s, sys: 276 ms, total: 52.2 s\n",
      "Wall time: 51.9 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "df_sample = df.sample(1000, random_state=2008)\n",
    "df_sample[\"food_items\"] = df_sample[\"clean_review\"].apply(search_food)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>loc</th>\n",
       "      <th>title</th>\n",
       "      <th>body</th>\n",
       "      <th>restaurant.name</th>\n",
       "      <th>review_text</th>\n",
       "      <th>hashtags</th>\n",
       "      <th>mentions</th>\n",
       "      <th>dollars</th>\n",
       "      <th>scores</th>\n",
       "      <th>urls</th>\n",
       "      <th>clean_review</th>\n",
       "      <th>food_items</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>242662</th>\n",
       "      <td>burppleinitial/review/jnF_zvaY</td>\n",
       "      <td>Aged Cheddar, Fig &amp; #Cognac Jam and Candied Wa...</td>\n",
       "      <td>Aged Cheddar, Fig &amp; #Cognac Jam and Candied Wa...</td>\n",
       "      <td>The Humble Loaf</td>\n",
       "      <td>Aged Cheddar, Fig and Jam and Candied Walnuts ...</td>\n",
       "      <td>(#Cognac, #lunch, #weekend, #Cognac, #lunch, #...</td>\n",
       "      <td>()</td>\n",
       "      <td>()</td>\n",
       "      <td>()</td>\n",
       "      <td>()</td>\n",
       "      <td>aged cheddar fig and jam and candied walnuts o...</td>\n",
       "      <td>[toast, jam, walnuts]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>74846</th>\n",
       "      <td>burppleinitial/review/CzDetUln</td>\n",
       "      <td>Orange Brioche</td>\n",
       "      <td></td>\n",
       "      <td>Artisan Boulangerie Co. (Great World City)</td>\n",
       "      <td>Orange Brioche</td>\n",
       "      <td>()</td>\n",
       "      <td>()</td>\n",
       "      <td>()</td>\n",
       "      <td>()</td>\n",
       "      <td>()</td>\n",
       "      <td>orange brioche</td>\n",
       "      <td>[orange brioche]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                   loc  \\\n",
       "242662  burppleinitial/review/jnF_zvaY   \n",
       "74846   burppleinitial/review/CzDetUln   \n",
       "\n",
       "                                                    title  \\\n",
       "242662  Aged Cheddar, Fig & #Cognac Jam and Candied Wa...   \n",
       "74846                                      Orange Brioche   \n",
       "\n",
       "                                                     body  \\\n",
       "242662  Aged Cheddar, Fig & #Cognac Jam and Candied Wa...   \n",
       "74846                                                       \n",
       "\n",
       "                                   restaurant.name  \\\n",
       "242662                             The Humble Loaf   \n",
       "74846   Artisan Boulangerie Co. (Great World City)   \n",
       "\n",
       "                                              review_text  \\\n",
       "242662  Aged Cheddar, Fig and Jam and Candied Walnuts ...   \n",
       "74846                                      Orange Brioche   \n",
       "\n",
       "                                                 hashtags mentions dollars  \\\n",
       "242662  (#Cognac, #lunch, #weekend, #Cognac, #lunch, #...       ()      ()   \n",
       "74846                                                  ()       ()      ()   \n",
       "\n",
       "       scores urls                                       clean_review  \\\n",
       "242662     ()   ()  aged cheddar fig and jam and candied walnuts o...   \n",
       "74846      ()   ()                                     orange brioche   \n",
       "\n",
       "                   food_items  \n",
       "242662  [toast, jam, walnuts]  \n",
       "74846        [orange brioche]  "
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_sample.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\"\"\"\n",
    "CPU times: user 4h 37min 15s, sys: 58.5 s, total: 4h 38min 14s\n",
    "Wall time: 4h 37min 12s\n",
    "\"\"\"\n",
    "if 1==1:\n",
    "    df[\"food_items\"] = df[\"clean_review\"].apply(search_food)\n",
    "    file_name = \"burpple__review__food__\"+f.today()+\".p\" \n",
    "    f.save_file(df, file_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.sample(20, random_state=2008)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
